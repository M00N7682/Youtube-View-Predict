{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056a2856",
   "metadata": {},
   "source": [
    "라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46c1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## library import - data preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908d5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT embedding \n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85065246",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b31b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 평가 지표 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score, mean_squared_error\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a498e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebdf2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 한글 폰트 설정 (윈도우용)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 마이너스 부호 깨짐 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b803d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm \n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84df8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# kaggle hub\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3331a",
   "metadata": {},
   "source": [
    "데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca5e11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kagglehub[pandas-datasets] in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (0.3.12)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (4.64.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (21.3)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (6.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (2.27.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (1.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->kagglehub[pandas-datasets]) (3.0.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->kagglehub[pandas-datasets]) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->kagglehub[pandas-datasets]) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18baef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\user\\.cache\\kagglehub\\datasets\\datasnaek\\youtube-new\\versions\\115\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"datasnaek/youtube-new\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13fdadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load USvideo Dataset\n",
    "df = pd.read_csv(os.path.join(path, \"USvideos.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8441e696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>last week tonight trump presidency|\"last week ...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>rhett and link|\"gmm\"|\"good mythical morning\"|\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d380meD0W0M</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
       "      <td>2095731</td>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE      17.14.11   \n",
       "1  1ZAPwfrtAFY      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  puqaWrEC7tY      17.14.11   \n",
       "4  d380meD0W0M      17.14.11   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "4                           I Dare You: GOING BALD!?               nigahiga   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           22  2017-11-13T17:13:01.000Z   \n",
       "1           24  2017-11-13T07:30:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "3           24  2017-11-13T11:00:04.000Z   \n",
       "4           24  2017-11-12T18:01:41.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
       "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
       "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
       "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  \n",
       "4  I know it's been a while since we did this sho...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9da67a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40949 entries, 0 to 40948\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40949 non-null  object\n",
      " 1   trending_date           40949 non-null  object\n",
      " 2   title                   40949 non-null  object\n",
      " 3   channel_title           40949 non-null  object\n",
      " 4   category_id             40949 non-null  int64 \n",
      " 5   publish_time            40949 non-null  object\n",
      " 6   tags                    40949 non-null  object\n",
      " 7   views                   40949 non-null  int64 \n",
      " 8   likes                   40949 non-null  int64 \n",
      " 9   dislikes                40949 non-null  int64 \n",
      " 10  comment_count           40949 non-null  int64 \n",
      " 11  thumbnail_link          40949 non-null  object\n",
      " 12  comments_disabled       40949 non-null  bool  \n",
      " 13  ratings_disabled        40949 non-null  bool  \n",
      " 14  video_error_or_removed  40949 non-null  bool  \n",
      " 15  description             40379 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인 \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c4944",
   "metadata": {},
   "source": [
    "data prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36490d1",
   "metadata": {},
   "source": [
    "Null/duplicate check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4acabf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                    0\n",
       "trending_date               0\n",
       "title                       0\n",
       "channel_title               0\n",
       "category_id                 0\n",
       "publish_time                0\n",
       "tags                        0\n",
       "views                       0\n",
       "likes                       0\n",
       "dislikes                    0\n",
       "comment_count               0\n",
       "thumbnail_link              0\n",
       "comments_disabled           0\n",
       "ratings_disabled            0\n",
       "video_error_or_removed      0\n",
       "description               570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "778c506d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 확인 \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcdd2956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34899</th>\n",
       "      <td>QBL8IRJ5yHU</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Why I'm So Scared (being myself and crying too...</td>\n",
       "      <td>grav3yardgirl</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-05-14T19:00:01.000Z</td>\n",
       "      <td>beauty|\"how to\"|\"makeup\"|\"howto\"|\"style\"|\"fash...</td>\n",
       "      <td>1469627</td>\n",
       "      <td>188652</td>\n",
       "      <td>3124</td>\n",
       "      <td>33032</td>\n",
       "      <td>https://i.ytimg.com/vi/QBL8IRJ5yHU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I will never be able to say Thank You enough.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34900</th>\n",
       "      <td>t4pRQ0jn23Q</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>YoungBoy Never Broke Again Goes Sneaker Shoppi...</td>\n",
       "      <td>Complex</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-14T14:00:03.000Z</td>\n",
       "      <td>sneakerhead|\"complex\"|\"complex originals\"|\"sne...</td>\n",
       "      <td>1199587</td>\n",
       "      <td>49709</td>\n",
       "      <td>2380</td>\n",
       "      <td>7261</td>\n",
       "      <td>https://i.ytimg.com/vi/t4pRQ0jn23Q/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>YoungBoy Never Broke Again goes Sneaker Shoppi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34901</th>\n",
       "      <td>j4KvrAUjn6c</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>WE MADE OUR MOM CRY...HER DREAM CAME TRUE!</td>\n",
       "      <td>Lucas and Marcus</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-13T18:03:56.000Z</td>\n",
       "      <td>Lucas and Marcus|\"Marcus and Lucas\"|\"Dobre\"|\"D...</td>\n",
       "      <td>3906727</td>\n",
       "      <td>77378</td>\n",
       "      <td>12160</td>\n",
       "      <td>15874</td>\n",
       "      <td>https://i.ytimg.com/vi/j4KvrAUjn6c/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BEST MOM EVER! WANT TO SEE US IN NYC &amp; NJ?!BUY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34902</th>\n",
       "      <td>MAjY8mCTXWk</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>周杰倫 Jay Chou【不愛我就拉倒 If You Don't Love Me, It's...</td>\n",
       "      <td>杰威爾音樂 JVR Music</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-05-14T15:59:47.000Z</td>\n",
       "      <td>周杰倫|\"Jay\"|\"Chou\"|\"周董\"|\"周杰伦\"|\"周傑倫\"|\"杰威尔\"|\"周周\"|\"...</td>\n",
       "      <td>916128</td>\n",
       "      <td>40485</td>\n",
       "      <td>1042</td>\n",
       "      <td>4746</td>\n",
       "      <td>https://i.ytimg.com/vi/MAjY8mCTXWk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>詞：周杰倫、宋健彰（彈頭）  曲：周杰倫憂鬱型男的走心旋律  用英式搖滾宣洩情傷不愛我就拉倒...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34903</th>\n",
       "      <td>xhs8tf1v__w</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Terry Crews Answers the Web's Most Searched Qu...</td>\n",
       "      <td>WIRED</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-14T16:00:29.000Z</td>\n",
       "      <td>autocomplete|\"deadpool 2\"|\"google autocomplete...</td>\n",
       "      <td>343967</td>\n",
       "      <td>16988</td>\n",
       "      <td>132</td>\n",
       "      <td>1308</td>\n",
       "      <td>https://i.ytimg.com/vi/xhs8tf1v__w/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Terry Crews takes the WIRED Autocomplete Inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34904</th>\n",
       "      <td>E21NATEP9QI</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Why Stradivarius violins are worth millions</td>\n",
       "      <td>Vox</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-05-14T12:00:03.000Z</td>\n",
       "      <td>vox.com|\"vox\"|\"explain\"|\"stradivarius\"|\"violin...</td>\n",
       "      <td>433833</td>\n",
       "      <td>12356</td>\n",
       "      <td>307</td>\n",
       "      <td>1129</td>\n",
       "      <td>https://i.ytimg.com/vi/E21NATEP9QI/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Many musicians prefer these 300-year-old instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34905</th>\n",
       "      <td>jzLlsbdrwQk</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>$17 Pet vs. $100,000 Pet</td>\n",
       "      <td>BuzzFeedBlue</td>\n",
       "      <td>22</td>\n",
       "      <td>2018-05-13T15:00:57.000Z</td>\n",
       "      <td>buzzfeed|\"worth it\"|\"cheap vs. expensive\"|\"ste...</td>\n",
       "      <td>3081033</td>\n",
       "      <td>60379</td>\n",
       "      <td>6857</td>\n",
       "      <td>7796</td>\n",
       "      <td>https://i.ytimg.com/vi/jzLlsbdrwQk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>“Who is Lennox and why is he so special?”Credi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34906</th>\n",
       "      <td>1RZYOeQeIXE</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Sarah Paulson Gets Scared During '5 Second Rule'</td>\n",
       "      <td>TheEllenShow</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-14T13:00:00.000Z</td>\n",
       "      <td>ellen|\"ellen degeneres\"|\"the ellen show\"|\"seas...</td>\n",
       "      <td>704786</td>\n",
       "      <td>19880</td>\n",
       "      <td>248</td>\n",
       "      <td>669</td>\n",
       "      <td>https://i.ytimg.com/vi/1RZYOeQeIXE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sarah Paulson agreed to play a friendly game o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34907</th>\n",
       "      <td>WF82ABLw8s4</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Gabby Barrett Sings I Have Nothing by Whitney ...</td>\n",
       "      <td>American Idol</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-14T02:23:01.000Z</td>\n",
       "      <td>ABC|\"americanidol\"|\"idol\"|\"american idol\"|\"rya...</td>\n",
       "      <td>735031</td>\n",
       "      <td>11734</td>\n",
       "      <td>1468</td>\n",
       "      <td>1870</td>\n",
       "      <td>https://i.ytimg.com/vi/WF82ABLw8s4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Gabby Barrett sings I Have Nothing by Whitney ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34908</th>\n",
       "      <td>r-3iathMo7o</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>The ULTIMATE $30,000 Gaming PC Setup</td>\n",
       "      <td>Unbox Therapy</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-05-13T19:00:25.000Z</td>\n",
       "      <td>gaming setup|\"gaming\"|\"setup\"|\"fortnite\"|\"fort...</td>\n",
       "      <td>4700460</td>\n",
       "      <td>103430</td>\n",
       "      <td>8028</td>\n",
       "      <td>13293</td>\n",
       "      <td>https://i.ytimg.com/vi/r-3iathMo7o/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Fortnite, PUBG, Far Cry 5? Which game would yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34909</th>\n",
       "      <td>NBSAQenU2Bk</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Rooster Teeth Animated Adventures - Millie So ...</td>\n",
       "      <td>Rooster Teeth</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-14T13:00:01.000Z</td>\n",
       "      <td>Rooster Teeth|\"RT\"|\"animation\"|\"television\"|\"f...</td>\n",
       "      <td>404162</td>\n",
       "      <td>17920</td>\n",
       "      <td>79</td>\n",
       "      <td>642</td>\n",
       "      <td>https://i.ytimg.com/vi/NBSAQenU2Bk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Millie is invited to help out at a Sugar Pine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34910</th>\n",
       "      <td>Xpv-sEKl1B4</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Why You Should Wake Up at 4:30 AM Every Day, A...</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-05-13T20:00:02.000Z</td>\n",
       "      <td>Business Insider|\"Business News\"|\"scheduling\"|...</td>\n",
       "      <td>2567982</td>\n",
       "      <td>50065</td>\n",
       "      <td>2345</td>\n",
       "      <td>6732</td>\n",
       "      <td>https://i.ytimg.com/vi/Xpv-sEKl1B4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>With a busy schedule, Jocko Willink finds time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34911</th>\n",
       "      <td>HrQNdClwMs4</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>DIY GIANT McDONALDS HASH BROWN 🍟 - VERSUS</td>\n",
       "      <td>HellthyJunkFood</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-13T13:00:01.000Z</td>\n",
       "      <td>mcdonalds hashbrown|\"mcdonalds\"|\"hash brown\"|\"...</td>\n",
       "      <td>1957964</td>\n",
       "      <td>25829</td>\n",
       "      <td>2643</td>\n",
       "      <td>3698</td>\n",
       "      <td>https://i.ytimg.com/vi/HrQNdClwMs4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SUBSCRIBE HERE ➡️ https://goo.gl/CitGia2ND CHA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34913</th>\n",
       "      <td>4oqvNR1o3Zo</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>24 HOUR BOX FORT PRISON ESCAPE ROOM!! 📦🚔 Diggi...</td>\n",
       "      <td>Papa Jake</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-13T16:42:33.000Z</td>\n",
       "      <td>box fort|\"fort\"|\"kids\"|\"funny\"|\"fun\"|\"no swear...</td>\n",
       "      <td>1030616</td>\n",
       "      <td>20251</td>\n",
       "      <td>3290</td>\n",
       "      <td>3567</td>\n",
       "      <td>https://i.ytimg.com/vi/4oqvNR1o3Zo/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>In Todays 24 hour Box Fort video papa Jake bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34914</th>\n",
       "      <td>96oKlWv5wSo</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>AMAZING All You Can Eat  BBQ KEBAB Buffet in I...</td>\n",
       "      <td>Strictly Dumpling</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-05-13T20:17:14.000Z</td>\n",
       "      <td>indian buffet|\"kebab buffet\"|\"buffet\"|\"all you...</td>\n",
       "      <td>456475</td>\n",
       "      <td>10561</td>\n",
       "      <td>337</td>\n",
       "      <td>1384</td>\n",
       "      <td>https://i.ytimg.com/vi/96oKlWv5wSo/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I'm always on the lookout for new amazing buff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34915</th>\n",
       "      <td>oRexsyztGS0</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Exciting iPhone 11 Leaks &amp; Round Apple Watch!</td>\n",
       "      <td>EverythingApplePro</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-13T18:29:09.000Z</td>\n",
       "      <td>iPhone 11|\"iphone 11 leaks\"|\"2018 iphone\"|\"iph...</td>\n",
       "      <td>963996</td>\n",
       "      <td>20323</td>\n",
       "      <td>1108</td>\n",
       "      <td>3323</td>\n",
       "      <td>https://i.ytimg.com/vi/oRexsyztGS0/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>iPhone 11 Leaks Are Ramping Up, Latest Feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34916</th>\n",
       "      <td>MT7RQ0gu8ak</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>DO PARENTS KNOW MODERN MUSIC? #17 (REACT: Do T...</td>\n",
       "      <td>REACT</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-13T19:00:01.000Z</td>\n",
       "      <td>Modern music|\"Do parents know modern music\"|\"n...</td>\n",
       "      <td>800873</td>\n",
       "      <td>19909</td>\n",
       "      <td>744</td>\n",
       "      <td>5017</td>\n",
       "      <td>https://i.ytimg.com/vi/MT7RQ0gu8ak/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Watch all Do They Know It Eps! https://goo.gl/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34917</th>\n",
       "      <td>1U1u5aKU3AY</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>New lava fissures fuel fears of eruption in Ha...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-05-13T19:30:53.000Z</td>\n",
       "      <td>latest News|\"Happening Now\"|\"CNN\"|\"lava\"|\"hawa...</td>\n",
       "      <td>241387</td>\n",
       "      <td>1488</td>\n",
       "      <td>251</td>\n",
       "      <td>1087</td>\n",
       "      <td>https://i.ytimg.com/vi/1U1u5aKU3AY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Three new fissures have opened on Hawaii's Big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34918</th>\n",
       "      <td>xTrwT0jSUg0</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Mother Knows Best - SNL</td>\n",
       "      <td>Saturday Night Live</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-13T05:06:11.000Z</td>\n",
       "      <td>SNL|\"Saturday Night Live\"|\"SNL Season 43\"|\"SNL...</td>\n",
       "      <td>1248343</td>\n",
       "      <td>15750</td>\n",
       "      <td>1919</td>\n",
       "      <td>1261</td>\n",
       "      <td>https://i.ytimg.com/vi/xTrwT0jSUg0/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Three mother-child pairs (Cecily Strong, Aidy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34919</th>\n",
       "      <td>3g5O-kT9m8k</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>$1000 Survival Kit in a Case</td>\n",
       "      <td>CrazyRussianHacker</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-05-13T18:51:13.000Z</td>\n",
       "      <td>$1000 Survival Kit|\"Survival Kit in a Case\"|\"p...</td>\n",
       "      <td>1289899</td>\n",
       "      <td>51318</td>\n",
       "      <td>1359</td>\n",
       "      <td>4332</td>\n",
       "      <td>https://i.ytimg.com/vi/3g5O-kT9m8k/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>$15 Survival Kit Unboxing - https://youtu.be/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34921</th>\n",
       "      <td>Dwc27Lsr1EY</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>MANIFEST | Official Trailer | NBC Fall Shows 2018</td>\n",
       "      <td>Manifest</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-13T16:29:55.000Z</td>\n",
       "      <td>NBC|\"2018\"|\"New Show\"|\"trailer\"|\"promo\"|\"plane...</td>\n",
       "      <td>2061448</td>\n",
       "      <td>5290</td>\n",
       "      <td>1861</td>\n",
       "      <td>546</td>\n",
       "      <td>https://i.ytimg.com/vi/Dwc27Lsr1EY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>In 2013, Flight 828 disappeared into thin air....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34922</th>\n",
       "      <td>6ijnv-jNhUA</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Make a Glowing Announcement Board</td>\n",
       "      <td>The King of Random</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-05-13T15:00:00.000Z</td>\n",
       "      <td>how to make a brilliant board|\"bright board\"|\"...</td>\n",
       "      <td>454162</td>\n",
       "      <td>9815</td>\n",
       "      <td>330</td>\n",
       "      <td>1489</td>\n",
       "      <td>https://i.ytimg.com/vi/6ijnv-jNhUA/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>In today's video we're making a cool glowing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34923</th>\n",
       "      <td>D2mxKEa2xmA</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>10 Most DEVASTATING Cyber Attacks in History</td>\n",
       "      <td>MatthewSantoro</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-13T13:00:01.000Z</td>\n",
       "      <td>computer hacks|\"cyber attack\"|\"computer virus\"...</td>\n",
       "      <td>158406</td>\n",
       "      <td>6773</td>\n",
       "      <td>364</td>\n",
       "      <td>947</td>\n",
       "      <td>https://i.ytimg.com/vi/D2mxKEa2xmA/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Download the best VPN on the market, NORDVPN n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34924</th>\n",
       "      <td>OUBx_raReDw</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Amanda Nunes vs Raquel Pennington | HIGHLIGHTS...</td>\n",
       "      <td>UFC ON FOX</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-05-13T06:44:47.000Z</td>\n",
       "      <td>mma|\"ufc\"|\"amanda nunes\"|\"main event\"|\"raquel ...</td>\n",
       "      <td>769802</td>\n",
       "      <td>2777</td>\n",
       "      <td>667</td>\n",
       "      <td>1285</td>\n",
       "      <td>https://i.ytimg.com/vi/OUBx_raReDw/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The UFC on FOX crew breaks down Nunes' dominan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34925</th>\n",
       "      <td>BspHjvU11y4</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Kelly Clarkson - Meaning of Life [Official Video]</td>\n",
       "      <td>Kelly Clarkson</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-05-13T13:00:41.000Z</td>\n",
       "      <td>Kelly Clarkson|\"Meaning of Life\"|\"mol\"|\"Offici...</td>\n",
       "      <td>494211</td>\n",
       "      <td>28080</td>\n",
       "      <td>426</td>\n",
       "      <td>1644</td>\n",
       "      <td>https://i.ytimg.com/vi/BspHjvU11y4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>MEANING OF LIFE available now: https://Atlanti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34926</th>\n",
       "      <td>nRc0kmOYgzQ</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>We built the Infinity Gauntlet with 25,000 mag...</td>\n",
       "      <td>Vat19</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-12T11:30:03.000Z</td>\n",
       "      <td>vat19|\"vat19 nanodots\"|\"vat19 infinity gauntle...</td>\n",
       "      <td>2227658</td>\n",
       "      <td>29191</td>\n",
       "      <td>1157</td>\n",
       "      <td>4092</td>\n",
       "      <td>https://i.ytimg.com/vi/nRc0kmOYgzQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NanoDots master builder, Edo, turned a huge pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34927</th>\n",
       "      <td>UfKmSfgFxi8</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>FORTNITE The Movie (Official Fake Trailer)</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-11T21:11:16.000Z</td>\n",
       "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"fortnite\"|\"th...</td>\n",
       "      <td>8289563</td>\n",
       "      <td>408385</td>\n",
       "      <td>10966</td>\n",
       "      <td>21837</td>\n",
       "      <td>https://i.ytimg.com/vi/UfKmSfgFxi8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Play Fortnite for FREE here: https://pixly.go2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34928</th>\n",
       "      <td>_iGAptGAweo</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Timed Mile in P.E. | Hannah Stocking &amp; Anwar J...</td>\n",
       "      <td>Hannah Stocking</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-05-12T16:01:05.000Z</td>\n",
       "      <td>timed mile in pe|\"hannah\"|\"stocking\"|\"anwar\"|\"...</td>\n",
       "      <td>2271926</td>\n",
       "      <td>78125</td>\n",
       "      <td>4191</td>\n",
       "      <td>5868</td>\n",
       "      <td>https://i.ytimg.com/vi/_iGAptGAweo/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MORE ▶ https://youtu.be/twi_5o62cbUSUBSC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34929</th>\n",
       "      <td>DGdSlnw4D_M</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Fortnite | Real Life Battle Royale!!</td>\n",
       "      <td>Team Edge</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-05-11T21:19:10.000Z</td>\n",
       "      <td>kids games|\"family games\"|\"challenges\"|\"compet...</td>\n",
       "      <td>2058569</td>\n",
       "      <td>32574</td>\n",
       "      <td>4195</td>\n",
       "      <td>5227</td>\n",
       "      <td>https://i.ytimg.com/vi/DGdSlnw4D_M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Team Edge Merchandise! ➡ https://teamedge.stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34930</th>\n",
       "      <td>BfawmhUVXVo</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>‘A Change Is Gonna Come’ for Lifford after he ...</td>\n",
       "      <td>Britain's Got Talent</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-12T19:46:33.000Z</td>\n",
       "      <td>britain's got talent|\"britains got talent\"|\"br...</td>\n",
       "      <td>1670008</td>\n",
       "      <td>25506</td>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/BfawmhUVXVo/default.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Former Artful Dodger collaborator Lifford Shil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34931</th>\n",
       "      <td>LtpqdJkoKm8</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>COLLEGE KIDS REACT TO THIS IS AMERICA - CHILDI...</td>\n",
       "      <td>FBE</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-11T21:00:03.000Z</td>\n",
       "      <td>this is america|\"childish gambino\"|\"donald glo...</td>\n",
       "      <td>3513129</td>\n",
       "      <td>106481</td>\n",
       "      <td>6922</td>\n",
       "      <td>18647</td>\n",
       "      <td>https://i.ytimg.com/vi/LtpqdJkoKm8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>This is America by Childish Gambino reacted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34932</th>\n",
       "      <td>mAfkkgw_-68</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>We Tried To Re-Create This Giant Cinnamon Roll</td>\n",
       "      <td>Tasty</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-05-12T15:00:32.000Z</td>\n",
       "      <td>Buzzfeed|\"eating your feed\"|\"viral food\"|\"cinn...</td>\n",
       "      <td>1207080</td>\n",
       "      <td>28615</td>\n",
       "      <td>598</td>\n",
       "      <td>1537</td>\n",
       "      <td>https://i.ytimg.com/vi/mAfkkgw_-68/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>“OH MY GOD THEY”RE GIGANTIC!”Check us out on F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34933</th>\n",
       "      <td>rQEqKZ7CJlk</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Bangabandhu Satellite-1 Mission</td>\n",
       "      <td>SpaceX</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-05-11T20:56:59.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>2652713</td>\n",
       "      <td>46420</td>\n",
       "      <td>4450</td>\n",
       "      <td>5561</td>\n",
       "      <td>https://i.ytimg.com/vi/rQEqKZ7CJlk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SpaceX is targeting launch of Bangabandhu Sate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34934</th>\n",
       "      <td>OXVm3fhYsEo</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>KYLIE COSMETICS X KRIS JENNER COLLECTION | SWA...</td>\n",
       "      <td>Jaclyn Hill</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-05-11T22:25:51.000Z</td>\n",
       "      <td>jaclynhill1|\"jaclyn hill\"|\"makeup tutorial\"|\"s...</td>\n",
       "      <td>2288505</td>\n",
       "      <td>96852</td>\n",
       "      <td>5530</td>\n",
       "      <td>12492</td>\n",
       "      <td>https://i.ytimg.com/vi/OXVm3fhYsEo/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>*After looking over this footage, I definitely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34935</th>\n",
       "      <td>ksjWPxFPsos</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Can you Shrek it? (YIAY #414)</td>\n",
       "      <td>jacksfilms</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-05-11T19:20:29.000Z</td>\n",
       "      <td>Jacksfilms|\"Jack Douglass\"|\"YGS\"|\"YGS 100\"|\"YG...</td>\n",
       "      <td>1663506</td>\n",
       "      <td>79165</td>\n",
       "      <td>1879</td>\n",
       "      <td>36476</td>\n",
       "      <td>https://i.ytimg.com/vi/ksjWPxFPsos/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Get your first 3 meals free by going here! ► h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34936</th>\n",
       "      <td>UQkBcHLZOqU</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Wearing Fashion Nova Outfits For A Week</td>\n",
       "      <td>Safiya Nygaard</td>\n",
       "      <td>22</td>\n",
       "      <td>2018-05-11T22:36:56.000Z</td>\n",
       "      <td>wearing fashion nova outfits for a week|\"fashi...</td>\n",
       "      <td>4106029</td>\n",
       "      <td>205285</td>\n",
       "      <td>2180</td>\n",
       "      <td>11217</td>\n",
       "      <td>https://i.ytimg.com/vi/UQkBcHLZOqU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I've been seeing this mysterious hashtag #Nova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34937</th>\n",
       "      <td>mdWcaWBxxcY</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Rita Ora - Girls ft. Cardi B, Bebe Rexha &amp; Cha...</td>\n",
       "      <td>Rita Ora</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-11T09:23:16.000Z</td>\n",
       "      <td>Rita Ora|\"Rita\"|\"Ora\"|\"Your Song\"|\"Anywhere\"|\"...</td>\n",
       "      <td>4429079</td>\n",
       "      <td>189112</td>\n",
       "      <td>22383</td>\n",
       "      <td>18998</td>\n",
       "      <td>https://i.ytimg.com/vi/mdWcaWBxxcY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Rita Ora 'Girls' ft. Cardi B, Bebe Rexha &amp; Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34938</th>\n",
       "      <td>Am6NHDbj6XA</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Donald Glover on This is America Music Video</td>\n",
       "      <td>Jimmy Kimmel Live</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-11T07:30:00.000Z</td>\n",
       "      <td>abc|\"network\"|\"tv\"|\"television\"|\"late\"|\"night\"...</td>\n",
       "      <td>4867281</td>\n",
       "      <td>86356</td>\n",
       "      <td>10524</td>\n",
       "      <td>3122</td>\n",
       "      <td>https://i.ytimg.com/vi/Am6NHDbj6XA/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Donald talks about his huge new video for This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34939</th>\n",
       "      <td>vjSohj-Iclc</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Getting some air, Atlas?</td>\n",
       "      <td>BostonDynamics</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-05-10T19:56:28.000Z</td>\n",
       "      <td>Dynamic robots|\"Boston Dynamics\"|\"humanoid rob...</td>\n",
       "      <td>5650991</td>\n",
       "      <td>76461</td>\n",
       "      <td>2666</td>\n",
       "      <td>12187</td>\n",
       "      <td>https://i.ytimg.com/vi/vjSohj-Iclc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34940</th>\n",
       "      <td>CPjWgk0UXps</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>I Got My Apartment Professionally Organized</td>\n",
       "      <td>Michelle Khare</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-11T15:00:01.000Z</td>\n",
       "      <td>michelle khare|\"buzzfeed michelle\"|\"organize\"|...</td>\n",
       "      <td>1122213</td>\n",
       "      <td>28049</td>\n",
       "      <td>1299</td>\n",
       "      <td>1214</td>\n",
       "      <td>https://i.ytimg.com/vi/CPjWgk0UXps/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I worked with professional organizer Ashley Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34941</th>\n",
       "      <td>uxbQATBAXf8</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Deadpool 2 | With Apologies to David Beckham</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-10T14:24:29.000Z</td>\n",
       "      <td>Trailer|\"Deadpool\"|\"20th Century Fox (Producti...</td>\n",
       "      <td>15960127</td>\n",
       "      <td>374825</td>\n",
       "      <td>3823</td>\n",
       "      <td>9059</td>\n",
       "      <td>https://i.ytimg.com/vi/uxbQATBAXf8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Get your Deadpool 2 tickets at http://www.Dead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34942</th>\n",
       "      <td>y_WoOYybCro</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>How I Became The Fresh Prince of Bel-Air | STO...</td>\n",
       "      <td>Will Smith</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-05-10T16:08:58.000Z</td>\n",
       "      <td>comedy|\"entertainment\"|\"will smith\"|\"will\"|\"sm...</td>\n",
       "      <td>2055638</td>\n",
       "      <td>120377</td>\n",
       "      <td>752</td>\n",
       "      <td>4872</td>\n",
       "      <td>https://i.ytimg.com/vi/y_WoOYybCro/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The full story of how an ex-girlfriend, Arseni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34943</th>\n",
       "      <td>oSEeK9yDNQI</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Clash Royale: Meet the Rascals! (New Card!)</td>\n",
       "      <td>Clash Royale</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-05-10T13:19:23.000Z</td>\n",
       "      <td>Clash Royale|\"Clash Royale Game\"|\"Supercell\"|\"...</td>\n",
       "      <td>13418844</td>\n",
       "      <td>258720</td>\n",
       "      <td>22805</td>\n",
       "      <td>19877</td>\n",
       "      <td>https://i.ytimg.com/vi/oSEeK9yDNQI/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Rascals! What have they done now...New Card Ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34944</th>\n",
       "      <td>iILJvqrAQ_w</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Charlie Puth - BOY [Official Audio]</td>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-05-11T04:00:34.000Z</td>\n",
       "      <td>charlie puth|\"boy\"|\"charlie\"|\"puth\"|\"atlantic\"...</td>\n",
       "      <td>2124177</td>\n",
       "      <td>81085</td>\n",
       "      <td>1321</td>\n",
       "      <td>4019</td>\n",
       "      <td>https://i.ytimg.com/vi/iILJvqrAQ_w/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Voicenotes Available Now: https://Atlantic.lnk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34945</th>\n",
       "      <td>zcEE8J2Bqa8</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>The Goblin - JACK AND DEAN</td>\n",
       "      <td>Jack and Dean</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-05-11T18:27:01.000Z</td>\n",
       "      <td>Jack and Dean|\"OMFGItsJackAndDean\"|\"Jack Howar...</td>\n",
       "      <td>165617</td>\n",
       "      <td>20572</td>\n",
       "      <td>140</td>\n",
       "      <td>1407</td>\n",
       "      <td>https://i.ytimg.com/vi/zcEE8J2Bqa8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>That? That's a goblin living under the stairs....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34946</th>\n",
       "      <td>q1jzwV_s8_Y</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Christina Aguilera - Twice (Audio)</td>\n",
       "      <td>CAguileraVEVO</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-05-11T07:00:01.000Z</td>\n",
       "      <td>Christina Aguilera|\"Pop\"|\"RCA Records Label\"|\"...</td>\n",
       "      <td>1869585</td>\n",
       "      <td>64523</td>\n",
       "      <td>1891</td>\n",
       "      <td>5903</td>\n",
       "      <td>https://i.ytimg.com/vi/q1jzwV_s8_Y/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Pre-order Christina Aguilera’s new album ‘Libe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34947</th>\n",
       "      <td>mkz1zoo15zI</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>Richard Jefferson and Tracy McGrady have stron...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-05-11T19:21:53.000Z</td>\n",
       "      <td>espn|\"espn live\"|\"dwane casey\"|\"raptors\"|\"toro...</td>\n",
       "      <td>472999</td>\n",
       "      <td>3505</td>\n",
       "      <td>163</td>\n",
       "      <td>1511</td>\n",
       "      <td>https://i.ytimg.com/vi/mkz1zoo15zI/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Richard Jefferson and Tracy McGrady share thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34948</th>\n",
       "      <td>2PH7dK6SLC8</td>\n",
       "      <td>18.15.05</td>\n",
       "      <td>John Mayer - New Light</td>\n",
       "      <td>johnmayerVEVO</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-05-10T17:00:01.000Z</td>\n",
       "      <td>John|\"Mayer\"|\"New\"|\"Light\"|\"Snack\"|\"Money\"|\"Po...</td>\n",
       "      <td>1201548</td>\n",
       "      <td>51670</td>\n",
       "      <td>964</td>\n",
       "      <td>4264</td>\n",
       "      <td>https://i.ytimg.com/vi/2PH7dK6SLC8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Spotify: http://radi.al/NewLightSpotifyApple: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id trending_date  \\\n",
       "34899  QBL8IRJ5yHU      18.15.05   \n",
       "34900  t4pRQ0jn23Q      18.15.05   \n",
       "34901  j4KvrAUjn6c      18.15.05   \n",
       "34902  MAjY8mCTXWk      18.15.05   \n",
       "34903  xhs8tf1v__w      18.15.05   \n",
       "34904  E21NATEP9QI      18.15.05   \n",
       "34905  jzLlsbdrwQk      18.15.05   \n",
       "34906  1RZYOeQeIXE      18.15.05   \n",
       "34907  WF82ABLw8s4      18.15.05   \n",
       "34908  r-3iathMo7o      18.15.05   \n",
       "34909  NBSAQenU2Bk      18.15.05   \n",
       "34910  Xpv-sEKl1B4      18.15.05   \n",
       "34911  HrQNdClwMs4      18.15.05   \n",
       "34913  4oqvNR1o3Zo      18.15.05   \n",
       "34914  96oKlWv5wSo      18.15.05   \n",
       "34915  oRexsyztGS0      18.15.05   \n",
       "34916  MT7RQ0gu8ak      18.15.05   \n",
       "34917  1U1u5aKU3AY      18.15.05   \n",
       "34918  xTrwT0jSUg0      18.15.05   \n",
       "34919  3g5O-kT9m8k      18.15.05   \n",
       "34921  Dwc27Lsr1EY      18.15.05   \n",
       "34922  6ijnv-jNhUA      18.15.05   \n",
       "34923  D2mxKEa2xmA      18.15.05   \n",
       "34924  OUBx_raReDw      18.15.05   \n",
       "34925  BspHjvU11y4      18.15.05   \n",
       "34926  nRc0kmOYgzQ      18.15.05   \n",
       "34927  UfKmSfgFxi8      18.15.05   \n",
       "34928  _iGAptGAweo      18.15.05   \n",
       "34929  DGdSlnw4D_M      18.15.05   \n",
       "34930  BfawmhUVXVo      18.15.05   \n",
       "34931  LtpqdJkoKm8      18.15.05   \n",
       "34932  mAfkkgw_-68      18.15.05   \n",
       "34933  rQEqKZ7CJlk      18.15.05   \n",
       "34934  OXVm3fhYsEo      18.15.05   \n",
       "34935  ksjWPxFPsos      18.15.05   \n",
       "34936  UQkBcHLZOqU      18.15.05   \n",
       "34937  mdWcaWBxxcY      18.15.05   \n",
       "34938  Am6NHDbj6XA      18.15.05   \n",
       "34939  vjSohj-Iclc      18.15.05   \n",
       "34940  CPjWgk0UXps      18.15.05   \n",
       "34941  uxbQATBAXf8      18.15.05   \n",
       "34942  y_WoOYybCro      18.15.05   \n",
       "34943  oSEeK9yDNQI      18.15.05   \n",
       "34944  iILJvqrAQ_w      18.15.05   \n",
       "34945  zcEE8J2Bqa8      18.15.05   \n",
       "34946  q1jzwV_s8_Y      18.15.05   \n",
       "34947  mkz1zoo15zI      18.15.05   \n",
       "34948  2PH7dK6SLC8      18.15.05   \n",
       "\n",
       "                                                   title  \\\n",
       "34899  Why I'm So Scared (being myself and crying too...   \n",
       "34900  YoungBoy Never Broke Again Goes Sneaker Shoppi...   \n",
       "34901         WE MADE OUR MOM CRY...HER DREAM CAME TRUE!   \n",
       "34902  周杰倫 Jay Chou【不愛我就拉倒 If You Don't Love Me, It's...   \n",
       "34903  Terry Crews Answers the Web's Most Searched Qu...   \n",
       "34904        Why Stradivarius violins are worth millions   \n",
       "34905                           $17 Pet vs. $100,000 Pet   \n",
       "34906   Sarah Paulson Gets Scared During '5 Second Rule'   \n",
       "34907  Gabby Barrett Sings I Have Nothing by Whitney ...   \n",
       "34908               The ULTIMATE $30,000 Gaming PC Setup   \n",
       "34909  Rooster Teeth Animated Adventures - Millie So ...   \n",
       "34910  Why You Should Wake Up at 4:30 AM Every Day, A...   \n",
       "34911          DIY GIANT McDONALDS HASH BROWN 🍟 - VERSUS   \n",
       "34913  24 HOUR BOX FORT PRISON ESCAPE ROOM!! 📦🚔 Diggi...   \n",
       "34914  AMAZING All You Can Eat  BBQ KEBAB Buffet in I...   \n",
       "34915      Exciting iPhone 11 Leaks & Round Apple Watch!   \n",
       "34916  DO PARENTS KNOW MODERN MUSIC? #17 (REACT: Do T...   \n",
       "34917  New lava fissures fuel fears of eruption in Ha...   \n",
       "34918                            Mother Knows Best - SNL   \n",
       "34919                       $1000 Survival Kit in a Case   \n",
       "34921  MANIFEST | Official Trailer | NBC Fall Shows 2018   \n",
       "34922                  Make a Glowing Announcement Board   \n",
       "34923       10 Most DEVASTATING Cyber Attacks in History   \n",
       "34924  Amanda Nunes vs Raquel Pennington | HIGHLIGHTS...   \n",
       "34925  Kelly Clarkson - Meaning of Life [Official Video]   \n",
       "34926  We built the Infinity Gauntlet with 25,000 mag...   \n",
       "34927         FORTNITE The Movie (Official Fake Trailer)   \n",
       "34928  Timed Mile in P.E. | Hannah Stocking & Anwar J...   \n",
       "34929               Fortnite | Real Life Battle Royale!!   \n",
       "34930  ‘A Change Is Gonna Come’ for Lifford after he ...   \n",
       "34931  COLLEGE KIDS REACT TO THIS IS AMERICA - CHILDI...   \n",
       "34932     We Tried To Re-Create This Giant Cinnamon Roll   \n",
       "34933                    Bangabandhu Satellite-1 Mission   \n",
       "34934  KYLIE COSMETICS X KRIS JENNER COLLECTION | SWA...   \n",
       "34935                      Can you Shrek it? (YIAY #414)   \n",
       "34936            Wearing Fashion Nova Outfits For A Week   \n",
       "34937  Rita Ora - Girls ft. Cardi B, Bebe Rexha & Cha...   \n",
       "34938       Donald Glover on This is America Music Video   \n",
       "34939                           Getting some air, Atlas?   \n",
       "34940        I Got My Apartment Professionally Organized   \n",
       "34941       Deadpool 2 | With Apologies to David Beckham   \n",
       "34942  How I Became The Fresh Prince of Bel-Air | STO...   \n",
       "34943        Clash Royale: Meet the Rascals! (New Card!)   \n",
       "34944                Charlie Puth - BOY [Official Audio]   \n",
       "34945                         The Goblin - JACK AND DEAN   \n",
       "34946                 Christina Aguilera - Twice (Audio)   \n",
       "34947  Richard Jefferson and Tracy McGrady have stron...   \n",
       "34948                             John Mayer - New Light   \n",
       "\n",
       "              channel_title  category_id              publish_time  \\\n",
       "34899         grav3yardgirl           26  2018-05-14T19:00:01.000Z   \n",
       "34900               Complex           24  2018-05-14T14:00:03.000Z   \n",
       "34901      Lucas and Marcus           24  2018-05-13T18:03:56.000Z   \n",
       "34902       杰威爾音樂 JVR Music           10  2018-05-14T15:59:47.000Z   \n",
       "34903                 WIRED           24  2018-05-14T16:00:29.000Z   \n",
       "34904                   Vox           25  2018-05-14T12:00:03.000Z   \n",
       "34905          BuzzFeedBlue           22  2018-05-13T15:00:57.000Z   \n",
       "34906          TheEllenShow           24  2018-05-14T13:00:00.000Z   \n",
       "34907         American Idol           24  2018-05-14T02:23:01.000Z   \n",
       "34908         Unbox Therapy           28  2018-05-13T19:00:25.000Z   \n",
       "34909         Rooster Teeth            1  2018-05-14T13:00:01.000Z   \n",
       "34910      Business Insider           26  2018-05-13T20:00:02.000Z   \n",
       "34911       HellthyJunkFood           24  2018-05-13T13:00:01.000Z   \n",
       "34913             Papa Jake           24  2018-05-13T16:42:33.000Z   \n",
       "34914     Strictly Dumpling           19  2018-05-13T20:17:14.000Z   \n",
       "34915    EverythingApplePro           24  2018-05-13T18:29:09.000Z   \n",
       "34916                 REACT           24  2018-05-13T19:00:01.000Z   \n",
       "34917                   CNN           25  2018-05-13T19:30:53.000Z   \n",
       "34918   Saturday Night Live           24  2018-05-13T05:06:11.000Z   \n",
       "34919    CrazyRussianHacker           28  2018-05-13T18:51:13.000Z   \n",
       "34921              Manifest           24  2018-05-13T16:29:55.000Z   \n",
       "34922    The King of Random           27  2018-05-13T15:00:00.000Z   \n",
       "34923        MatthewSantoro           24  2018-05-13T13:00:01.000Z   \n",
       "34924            UFC ON FOX           17  2018-05-13T06:44:47.000Z   \n",
       "34925        Kelly Clarkson           10  2018-05-13T13:00:41.000Z   \n",
       "34926                 Vat19           24  2018-05-12T11:30:03.000Z   \n",
       "34927              nigahiga           24  2018-05-11T21:11:16.000Z   \n",
       "34928       Hannah Stocking           23  2018-05-12T16:01:05.000Z   \n",
       "34929             Team Edge           23  2018-05-11T21:19:10.000Z   \n",
       "34930  Britain's Got Talent           24  2018-05-12T19:46:33.000Z   \n",
       "34931                   FBE           24  2018-05-11T21:00:03.000Z   \n",
       "34932                 Tasty           26  2018-05-12T15:00:32.000Z   \n",
       "34933                SpaceX           28  2018-05-11T20:56:59.000Z   \n",
       "34934           Jaclyn Hill           26  2018-05-11T22:25:51.000Z   \n",
       "34935            jacksfilms           23  2018-05-11T19:20:29.000Z   \n",
       "34936        Safiya Nygaard           22  2018-05-11T22:36:56.000Z   \n",
       "34937              Rita Ora           24  2018-05-11T09:23:16.000Z   \n",
       "34938     Jimmy Kimmel Live           24  2018-05-11T07:30:00.000Z   \n",
       "34939        BostonDynamics           28  2018-05-10T19:56:28.000Z   \n",
       "34940        Michelle Khare           24  2018-05-11T15:00:01.000Z   \n",
       "34941      20th Century Fox            1  2018-05-10T14:24:29.000Z   \n",
       "34942            Will Smith           24  2018-05-10T16:08:58.000Z   \n",
       "34943          Clash Royale           20  2018-05-10T13:19:23.000Z   \n",
       "34944          Charlie Puth           10  2018-05-11T04:00:34.000Z   \n",
       "34945         Jack and Dean           23  2018-05-11T18:27:01.000Z   \n",
       "34946         CAguileraVEVO           10  2018-05-11T07:00:01.000Z   \n",
       "34947                  ESPN           17  2018-05-11T19:21:53.000Z   \n",
       "34948         johnmayerVEVO           10  2018-05-10T17:00:01.000Z   \n",
       "\n",
       "                                                    tags     views   likes  \\\n",
       "34899  beauty|\"how to\"|\"makeup\"|\"howto\"|\"style\"|\"fash...   1469627  188652   \n",
       "34900  sneakerhead|\"complex\"|\"complex originals\"|\"sne...   1199587   49709   \n",
       "34901  Lucas and Marcus|\"Marcus and Lucas\"|\"Dobre\"|\"D...   3906727   77378   \n",
       "34902  周杰倫|\"Jay\"|\"Chou\"|\"周董\"|\"周杰伦\"|\"周傑倫\"|\"杰威尔\"|\"周周\"|\"...    916128   40485   \n",
       "34903  autocomplete|\"deadpool 2\"|\"google autocomplete...    343967   16988   \n",
       "34904  vox.com|\"vox\"|\"explain\"|\"stradivarius\"|\"violin...    433833   12356   \n",
       "34905  buzzfeed|\"worth it\"|\"cheap vs. expensive\"|\"ste...   3081033   60379   \n",
       "34906  ellen|\"ellen degeneres\"|\"the ellen show\"|\"seas...    704786   19880   \n",
       "34907  ABC|\"americanidol\"|\"idol\"|\"american idol\"|\"rya...    735031   11734   \n",
       "34908  gaming setup|\"gaming\"|\"setup\"|\"fortnite\"|\"fort...   4700460  103430   \n",
       "34909  Rooster Teeth|\"RT\"|\"animation\"|\"television\"|\"f...    404162   17920   \n",
       "34910  Business Insider|\"Business News\"|\"scheduling\"|...   2567982   50065   \n",
       "34911  mcdonalds hashbrown|\"mcdonalds\"|\"hash brown\"|\"...   1957964   25829   \n",
       "34913  box fort|\"fort\"|\"kids\"|\"funny\"|\"fun\"|\"no swear...   1030616   20251   \n",
       "34914  indian buffet|\"kebab buffet\"|\"buffet\"|\"all you...    456475   10561   \n",
       "34915  iPhone 11|\"iphone 11 leaks\"|\"2018 iphone\"|\"iph...    963996   20323   \n",
       "34916  Modern music|\"Do parents know modern music\"|\"n...    800873   19909   \n",
       "34917  latest News|\"Happening Now\"|\"CNN\"|\"lava\"|\"hawa...    241387    1488   \n",
       "34918  SNL|\"Saturday Night Live\"|\"SNL Season 43\"|\"SNL...   1248343   15750   \n",
       "34919  $1000 Survival Kit|\"Survival Kit in a Case\"|\"p...   1289899   51318   \n",
       "34921  NBC|\"2018\"|\"New Show\"|\"trailer\"|\"promo\"|\"plane...   2061448    5290   \n",
       "34922  how to make a brilliant board|\"bright board\"|\"...    454162    9815   \n",
       "34923  computer hacks|\"cyber attack\"|\"computer virus\"...    158406    6773   \n",
       "34924  mma|\"ufc\"|\"amanda nunes\"|\"main event\"|\"raquel ...    769802    2777   \n",
       "34925  Kelly Clarkson|\"Meaning of Life\"|\"mol\"|\"Offici...    494211   28080   \n",
       "34926  vat19|\"vat19 nanodots\"|\"vat19 infinity gauntle...   2227658   29191   \n",
       "34927  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"fortnite\"|\"th...   8289563  408385   \n",
       "34928  timed mile in pe|\"hannah\"|\"stocking\"|\"anwar\"|\"...   2271926   78125   \n",
       "34929  kids games|\"family games\"|\"challenges\"|\"compet...   2058569   32574   \n",
       "34930  britain's got talent|\"britains got talent\"|\"br...   1670008   25506   \n",
       "34931  this is america|\"childish gambino\"|\"donald glo...   3513129  106481   \n",
       "34932  Buzzfeed|\"eating your feed\"|\"viral food\"|\"cinn...   1207080   28615   \n",
       "34933                                             [none]   2652713   46420   \n",
       "34934  jaclynhill1|\"jaclyn hill\"|\"makeup tutorial\"|\"s...   2288505   96852   \n",
       "34935  Jacksfilms|\"Jack Douglass\"|\"YGS\"|\"YGS 100\"|\"YG...   1663506   79165   \n",
       "34936  wearing fashion nova outfits for a week|\"fashi...   4106029  205285   \n",
       "34937  Rita Ora|\"Rita\"|\"Ora\"|\"Your Song\"|\"Anywhere\"|\"...   4429079  189112   \n",
       "34938  abc|\"network\"|\"tv\"|\"television\"|\"late\"|\"night\"...   4867281   86356   \n",
       "34939  Dynamic robots|\"Boston Dynamics\"|\"humanoid rob...   5650991   76461   \n",
       "34940  michelle khare|\"buzzfeed michelle\"|\"organize\"|...   1122213   28049   \n",
       "34941  Trailer|\"Deadpool\"|\"20th Century Fox (Producti...  15960127  374825   \n",
       "34942  comedy|\"entertainment\"|\"will smith\"|\"will\"|\"sm...   2055638  120377   \n",
       "34943  Clash Royale|\"Clash Royale Game\"|\"Supercell\"|\"...  13418844  258720   \n",
       "34944  charlie puth|\"boy\"|\"charlie\"|\"puth\"|\"atlantic\"...   2124177   81085   \n",
       "34945  Jack and Dean|\"OMFGItsJackAndDean\"|\"Jack Howar...    165617   20572   \n",
       "34946  Christina Aguilera|\"Pop\"|\"RCA Records Label\"|\"...   1869585   64523   \n",
       "34947  espn|\"espn live\"|\"dwane casey\"|\"raptors\"|\"toro...    472999    3505   \n",
       "34948  John|\"Mayer\"|\"New\"|\"Light\"|\"Snack\"|\"Money\"|\"Po...   1201548   51670   \n",
       "\n",
       "       dislikes  comment_count  \\\n",
       "34899      3124          33032   \n",
       "34900      2380           7261   \n",
       "34901     12160          15874   \n",
       "34902      1042           4746   \n",
       "34903       132           1308   \n",
       "34904       307           1129   \n",
       "34905      6857           7796   \n",
       "34906       248            669   \n",
       "34907      1468           1870   \n",
       "34908      8028          13293   \n",
       "34909        79            642   \n",
       "34910      2345           6732   \n",
       "34911      2643           3698   \n",
       "34913      3290           3567   \n",
       "34914       337           1384   \n",
       "34915      1108           3323   \n",
       "34916       744           5017   \n",
       "34917       251           1087   \n",
       "34918      1919           1261   \n",
       "34919      1359           4332   \n",
       "34921      1861            546   \n",
       "34922       330           1489   \n",
       "34923       364            947   \n",
       "34924       667           1285   \n",
       "34925       426           1644   \n",
       "34926      1157           4092   \n",
       "34927     10966          21837   \n",
       "34928      4191           5868   \n",
       "34929      4195           5227   \n",
       "34930       740              0   \n",
       "34931      6922          18647   \n",
       "34932       598           1537   \n",
       "34933      4450           5561   \n",
       "34934      5530          12492   \n",
       "34935      1879          36476   \n",
       "34936      2180          11217   \n",
       "34937     22383          18998   \n",
       "34938     10524           3122   \n",
       "34939      2666          12187   \n",
       "34940      1299           1214   \n",
       "34941      3823           9059   \n",
       "34942       752           4872   \n",
       "34943     22805          19877   \n",
       "34944      1321           4019   \n",
       "34945       140           1407   \n",
       "34946      1891           5903   \n",
       "34947       163           1511   \n",
       "34948       964           4264   \n",
       "\n",
       "                                       thumbnail_link  comments_disabled  \\\n",
       "34899  https://i.ytimg.com/vi/QBL8IRJ5yHU/default.jpg              False   \n",
       "34900  https://i.ytimg.com/vi/t4pRQ0jn23Q/default.jpg              False   \n",
       "34901  https://i.ytimg.com/vi/j4KvrAUjn6c/default.jpg              False   \n",
       "34902  https://i.ytimg.com/vi/MAjY8mCTXWk/default.jpg              False   \n",
       "34903  https://i.ytimg.com/vi/xhs8tf1v__w/default.jpg              False   \n",
       "34904  https://i.ytimg.com/vi/E21NATEP9QI/default.jpg              False   \n",
       "34905  https://i.ytimg.com/vi/jzLlsbdrwQk/default.jpg              False   \n",
       "34906  https://i.ytimg.com/vi/1RZYOeQeIXE/default.jpg              False   \n",
       "34907  https://i.ytimg.com/vi/WF82ABLw8s4/default.jpg              False   \n",
       "34908  https://i.ytimg.com/vi/r-3iathMo7o/default.jpg              False   \n",
       "34909  https://i.ytimg.com/vi/NBSAQenU2Bk/default.jpg              False   \n",
       "34910  https://i.ytimg.com/vi/Xpv-sEKl1B4/default.jpg              False   \n",
       "34911  https://i.ytimg.com/vi/HrQNdClwMs4/default.jpg              False   \n",
       "34913  https://i.ytimg.com/vi/4oqvNR1o3Zo/default.jpg              False   \n",
       "34914  https://i.ytimg.com/vi/96oKlWv5wSo/default.jpg              False   \n",
       "34915  https://i.ytimg.com/vi/oRexsyztGS0/default.jpg              False   \n",
       "34916  https://i.ytimg.com/vi/MT7RQ0gu8ak/default.jpg              False   \n",
       "34917  https://i.ytimg.com/vi/1U1u5aKU3AY/default.jpg              False   \n",
       "34918  https://i.ytimg.com/vi/xTrwT0jSUg0/default.jpg              False   \n",
       "34919  https://i.ytimg.com/vi/3g5O-kT9m8k/default.jpg              False   \n",
       "34921  https://i.ytimg.com/vi/Dwc27Lsr1EY/default.jpg              False   \n",
       "34922  https://i.ytimg.com/vi/6ijnv-jNhUA/default.jpg              False   \n",
       "34923  https://i.ytimg.com/vi/D2mxKEa2xmA/default.jpg              False   \n",
       "34924  https://i.ytimg.com/vi/OUBx_raReDw/default.jpg              False   \n",
       "34925  https://i.ytimg.com/vi/BspHjvU11y4/default.jpg              False   \n",
       "34926  https://i.ytimg.com/vi/nRc0kmOYgzQ/default.jpg              False   \n",
       "34927  https://i.ytimg.com/vi/UfKmSfgFxi8/default.jpg              False   \n",
       "34928  https://i.ytimg.com/vi/_iGAptGAweo/default.jpg              False   \n",
       "34929  https://i.ytimg.com/vi/DGdSlnw4D_M/default.jpg              False   \n",
       "34930  https://i.ytimg.com/vi/BfawmhUVXVo/default.jpg               True   \n",
       "34931  https://i.ytimg.com/vi/LtpqdJkoKm8/default.jpg              False   \n",
       "34932  https://i.ytimg.com/vi/mAfkkgw_-68/default.jpg              False   \n",
       "34933  https://i.ytimg.com/vi/rQEqKZ7CJlk/default.jpg              False   \n",
       "34934  https://i.ytimg.com/vi/OXVm3fhYsEo/default.jpg              False   \n",
       "34935  https://i.ytimg.com/vi/ksjWPxFPsos/default.jpg              False   \n",
       "34936  https://i.ytimg.com/vi/UQkBcHLZOqU/default.jpg              False   \n",
       "34937  https://i.ytimg.com/vi/mdWcaWBxxcY/default.jpg              False   \n",
       "34938  https://i.ytimg.com/vi/Am6NHDbj6XA/default.jpg              False   \n",
       "34939  https://i.ytimg.com/vi/vjSohj-Iclc/default.jpg              False   \n",
       "34940  https://i.ytimg.com/vi/CPjWgk0UXps/default.jpg              False   \n",
       "34941  https://i.ytimg.com/vi/uxbQATBAXf8/default.jpg              False   \n",
       "34942  https://i.ytimg.com/vi/y_WoOYybCro/default.jpg              False   \n",
       "34943  https://i.ytimg.com/vi/oSEeK9yDNQI/default.jpg              False   \n",
       "34944  https://i.ytimg.com/vi/iILJvqrAQ_w/default.jpg              False   \n",
       "34945  https://i.ytimg.com/vi/zcEE8J2Bqa8/default.jpg              False   \n",
       "34946  https://i.ytimg.com/vi/q1jzwV_s8_Y/default.jpg              False   \n",
       "34947  https://i.ytimg.com/vi/mkz1zoo15zI/default.jpg              False   \n",
       "34948  https://i.ytimg.com/vi/2PH7dK6SLC8/default.jpg              False   \n",
       "\n",
       "       ratings_disabled  video_error_or_removed  \\\n",
       "34899             False                   False   \n",
       "34900             False                   False   \n",
       "34901             False                   False   \n",
       "34902             False                   False   \n",
       "34903             False                   False   \n",
       "34904             False                   False   \n",
       "34905             False                   False   \n",
       "34906             False                   False   \n",
       "34907             False                   False   \n",
       "34908             False                   False   \n",
       "34909             False                   False   \n",
       "34910             False                   False   \n",
       "34911             False                   False   \n",
       "34913             False                   False   \n",
       "34914             False                   False   \n",
       "34915             False                   False   \n",
       "34916             False                   False   \n",
       "34917             False                   False   \n",
       "34918             False                   False   \n",
       "34919             False                   False   \n",
       "34921             False                   False   \n",
       "34922             False                   False   \n",
       "34923             False                   False   \n",
       "34924             False                   False   \n",
       "34925             False                   False   \n",
       "34926             False                   False   \n",
       "34927             False                   False   \n",
       "34928             False                   False   \n",
       "34929             False                   False   \n",
       "34930             False                   False   \n",
       "34931             False                   False   \n",
       "34932             False                   False   \n",
       "34933             False                   False   \n",
       "34934             False                   False   \n",
       "34935             False                   False   \n",
       "34936             False                   False   \n",
       "34937             False                   False   \n",
       "34938             False                   False   \n",
       "34939             False                   False   \n",
       "34940             False                   False   \n",
       "34941             False                   False   \n",
       "34942             False                   False   \n",
       "34943             False                   False   \n",
       "34944             False                   False   \n",
       "34945             False                   False   \n",
       "34946             False                   False   \n",
       "34947             False                   False   \n",
       "34948             False                   False   \n",
       "\n",
       "                                             description  \n",
       "34899  I will never be able to say Thank You enough.....  \n",
       "34900  YoungBoy Never Broke Again goes Sneaker Shoppi...  \n",
       "34901  BEST MOM EVER! WANT TO SEE US IN NYC & NJ?!BUY...  \n",
       "34902  詞：周杰倫、宋健彰（彈頭）  曲：周杰倫憂鬱型男的走心旋律  用英式搖滾宣洩情傷不愛我就拉倒...  \n",
       "34903  Terry Crews takes the WIRED Autocomplete Inter...  \n",
       "34904  Many musicians prefer these 300-year-old instr...  \n",
       "34905  “Who is Lennox and why is he so special?”Credi...  \n",
       "34906  Sarah Paulson agreed to play a friendly game o...  \n",
       "34907  Gabby Barrett sings I Have Nothing by Whitney ...  \n",
       "34908  Fortnite, PUBG, Far Cry 5? Which game would yo...  \n",
       "34909  Millie is invited to help out at a Sugar Pine ...  \n",
       "34910  With a busy schedule, Jocko Willink finds time...  \n",
       "34911  SUBSCRIBE HERE ➡️ https://goo.gl/CitGia2ND CHA...  \n",
       "34913  In Todays 24 hour Box Fort video papa Jake bui...  \n",
       "34914  I'm always on the lookout for new amazing buff...  \n",
       "34915  iPhone 11 Leaks Are Ramping Up, Latest Feature...  \n",
       "34916  Watch all Do They Know It Eps! https://goo.gl/...  \n",
       "34917  Three new fissures have opened on Hawaii's Big...  \n",
       "34918  Three mother-child pairs (Cecily Strong, Aidy ...  \n",
       "34919  $15 Survival Kit Unboxing - https://youtu.be/0...  \n",
       "34921  In 2013, Flight 828 disappeared into thin air....  \n",
       "34922  In today's video we're making a cool glowing b...  \n",
       "34923  Download the best VPN on the market, NORDVPN n...  \n",
       "34924  The UFC on FOX crew breaks down Nunes' dominan...  \n",
       "34925  MEANING OF LIFE available now: https://Atlanti...  \n",
       "34926  NanoDots master builder, Edo, turned a huge pi...  \n",
       "34927  Play Fortnite for FREE here: https://pixly.go2...  \n",
       "34928  WATCH MORE ▶ https://youtu.be/twi_5o62cbUSUBSC...  \n",
       "34929  Team Edge Merchandise! ➡ https://teamedge.stor...  \n",
       "34930  Former Artful Dodger collaborator Lifford Shil...  \n",
       "34931  This is America by Childish Gambino reacted to...  \n",
       "34932  “OH MY GOD THEY”RE GIGANTIC!”Check us out on F...  \n",
       "34933  SpaceX is targeting launch of Bangabandhu Sate...  \n",
       "34934  *After looking over this footage, I definitely...  \n",
       "34935  Get your first 3 meals free by going here! ► h...  \n",
       "34936  I've been seeing this mysterious hashtag #Nova...  \n",
       "34937  Rita Ora 'Girls' ft. Cardi B, Bebe Rexha & Cha...  \n",
       "34938  Donald talks about his huge new video for This...  \n",
       "34939                                                NaN  \n",
       "34940  I worked with professional organizer Ashley Mo...  \n",
       "34941  Get your Deadpool 2 tickets at http://www.Dead...  \n",
       "34942  The full story of how an ex-girlfriend, Arseni...  \n",
       "34943  Rascals! What have they done now...New Card Ou...  \n",
       "34944  Voicenotes Available Now: https://Atlantic.lnk...  \n",
       "34945  That? That's a goblin living under the stairs....  \n",
       "34946  Pre-order Christina Aguilera’s new album ‘Libe...  \n",
       "34947  Richard Jefferson and Tracy McGrady share thei...  \n",
       "34948  Spotify: http://radi.al/NewLightSpotifyApple: ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복된 행 확인 \n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39072bd4",
   "metadata": {},
   "source": [
    "category mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34e5345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 카테고리 매핑 \n",
    "# JSON 파일 경로\n",
    "json_path = os.path.join(path, \"US_category_id.json\")\n",
    "\n",
    "# JSON 로드\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    category_json = json.load(f)\n",
    "\n",
    "# 카테고리 매핑 딕셔너리 생성\n",
    "category_mapping = {\n",
    "    int(item['id']): item['snippet']['title']\n",
    "    for item in category_json['items']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86b579ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Film & Animation', 2: 'Autos & Vehicles', 10: 'Music', 15: 'Pets & Animals', 17: 'Sports', 18: 'Short Movies', 19: 'Travel & Events', 20: 'Gaming', 21: 'Videoblogging', 22: 'People & Blogs', 23: 'Comedy', 24: 'Entertainment', 25: 'News & Politics', 26: 'Howto & Style', 27: 'Education', 28: 'Science & Technology', 29: 'Nonprofits & Activism', 30: 'Movies', 31: 'Anime/Animation', 32: 'Action/Adventure', 33: 'Classics', 34: 'Comedy', 35: 'Documentary', 36: 'Drama', 37: 'Family', 38: 'Foreign', 39: 'Horror', 40: 'Sci-Fi/Fantasy', 41: 'Thriller', 42: 'Shorts', 43: 'Shows', 44: 'Trailers'}\n"
     ]
    }
   ],
   "source": [
    "# 매핑 딕셔너리 확인\n",
    "print(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03fca017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_name'] = df['category_id'].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c91c53a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          People & Blogs\n",
       "1           Entertainment\n",
       "2                  Comedy\n",
       "3           Entertainment\n",
       "4           Entertainment\n",
       "               ...       \n",
       "40944      Pets & Animals\n",
       "40945      People & Blogs\n",
       "40946       Entertainment\n",
       "40947    Film & Animation\n",
       "40948              Gaming\n",
       "Name: category_name, Length: 40949, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d73ff",
   "metadata": {},
   "source": [
    "target log-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f80ca727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-scaling 진행\n",
    "df['log_views'] = np.log1p(df['views'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03840b68",
   "metadata": {},
   "source": [
    "Modeling #1. category_id를 feature로 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33695bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>log_views</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>13.525659</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>14.698775</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>14.975981</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>12.745978</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>14.555413</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40944</th>\n",
       "      <td>The Cat Who Caught the Laser</td>\n",
       "      <td>14.337638</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40945</th>\n",
       "      <td>True Facts : Ant Mutualism</td>\n",
       "      <td>13.878297</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40946</th>\n",
       "      <td>I GAVE SAFIYA NYGAARD A PERFECT HAIR MAKEOVER ...</td>\n",
       "      <td>13.879848</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40947</th>\n",
       "      <td>How Black Panther Should Have Ended</td>\n",
       "      <td>15.549078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40948</th>\n",
       "      <td>Official Call of Duty®: Black Ops 4 — Multipla...</td>\n",
       "      <td>16.148248</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40949 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  log_views  \\\n",
       "0                     WE WANT TO TALK ABOUT OUR MARRIAGE  13.525659   \n",
       "1      The Trump Presidency: Last Week Tonight with J...  14.698775   \n",
       "2      Racist Superman | Rudy Mancuso, King Bach & Le...  14.975981   \n",
       "3                       Nickelback Lyrics: Real or Fake?  12.745978   \n",
       "4                               I Dare You: GOING BALD!?  14.555413   \n",
       "...                                                  ...        ...   \n",
       "40944                       The Cat Who Caught the Laser  14.337638   \n",
       "40945                         True Facts : Ant Mutualism  13.878297   \n",
       "40946  I GAVE SAFIYA NYGAARD A PERFECT HAIR MAKEOVER ...  13.879848   \n",
       "40947                How Black Panther Should Have Ended  15.549078   \n",
       "40948  Official Call of Duty®: Black Ops 4 — Multipla...  16.148248   \n",
       "\n",
       "       category_id  \n",
       "0               22  \n",
       "1               24  \n",
       "2               23  \n",
       "3               24  \n",
       "4               24  \n",
       "...            ...  \n",
       "40944           15  \n",
       "40945           22  \n",
       "40946           24  \n",
       "40947            1  \n",
       "40948           20  \n",
       "\n",
       "[40949 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category를 포함한 열 불러오기 \n",
    "category_df = df[['title', 'log_views', 'category_id']]\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afb17759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT load \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efb48b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT embedding extract \n",
    "\n",
    "## CLS 벡터 추출 함수 정의 \n",
    "\n",
    "def extract_cls_embedding(text):\n",
    "    encoding = tokenizer(text,\n",
    "                         max_length=32,\n",
    "                         truncation=True,\n",
    "                         padding='max_length',\n",
    "                         return_tensors='pt')\n",
    "    input_ids_tensor = encoding['input_ids'].to(device)\n",
    "    attention_mask_tensor = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    return cls_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdfa822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings = np.load(\"title_cls_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6217a9f",
   "metadata": {},
   "source": [
    "Modeling#2 category별 Model 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99682589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category별 데이터 수 확인 \n",
    "category_counts = df['category_name'].value_counts().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac5f3c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "category_counts.plot(kind='barh', color='skyblue')\n",
    "\n",
    "plt.title(\"카테고리별 데이터 샘플 수\", fontsize=14)\n",
    "plt.xlabel(\"샘플 수\", fontsize=12)\n",
    "plt.ylabel(\"category_id\", fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "065816a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3614589385.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_df['title_embedding'] = list(embeddings)\n"
     ]
    }
   ],
   "source": [
    "# BERT embedding에 category 결합\n",
    "category_df['title_embedding'] = list(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1174b2d",
   "metadata": {},
   "source": [
    "Howto&style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97b1ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category filtering\n",
    "cat_name = \"Howto & Style\"\n",
    "group = category_df[category_df['category_id'] == 26]\n",
    "\n",
    "X = np.vstack(group['title_embedding'].values)\n",
    "y = group['log_views']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92e7ab",
   "metadata": {},
   "source": [
    "Howto & Style - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32d6085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: Lasso\n",
      "Alpha: 0.0001\n",
      "RMSE: 0.5579\n",
      "R²: 0.829\n",
      "Spearman: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+02, tolerance: 5.771e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Lasso 모델 정의\n",
    "alpha_value = 0.0001\n",
    "lasso = Lasso(alpha=alpha_value)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# 성능 지표 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "\n",
    "# 출력\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: Lasso\")\n",
    "print(\"Alpha:\", alpha_value)\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", \"NaN\" if np.isnan(spearman_corr) else round(spearman_corr, 4))\n",
    "\n",
    "# 결과 저장 \n",
    "lasso_results_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"Lasso\",\n",
    "    \"Alpha\": alpha_value,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e0afc",
   "metadata": {},
   "source": [
    "Howto & Style - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f70d78b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: LinearRegression\n",
      "RMSE: 0.577\n",
      "R²: 0.8171\n",
      "Spearman: 0.9453\n"
     ]
    }
   ],
   "source": [
    "# LinearRegression 모델 정의 및 학습\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "y_pred = linear.predict(X_test)\n",
    "\n",
    "# 성능 지표 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "\n",
    "# 출력\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: LinearRegression\")\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", \"NaN\" if np.isnan(spearman_corr) else round(spearman_corr, 4))\n",
    "\n",
    "# 결과 저장\n",
    "linear_results_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"LinearRegression\",\n",
    "    \"Alpha\": None,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e2b34",
   "metadata": {},
   "source": [
    "Howto & Style - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5ec627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: Ridge\n",
      "Alpha: 1.0\n",
      "RMSE: 0.5708\n",
      "R²: 0.821\n",
      "Spearman: 0.9352\n"
     ]
    }
   ],
   "source": [
    "# Ridge 모델 정의 및 학습\n",
    "alpha_value = 1.0\n",
    "ridge = Ridge(alpha=alpha_value)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# 성능 지표 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "\n",
    "# 출력\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: Ridge\")\n",
    "print(\"Alpha:\", alpha_value)\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", \"NaN\" if np.isnan(spearman_corr) else round(spearman_corr, 4))\n",
    "\n",
    "# 결과 저장\n",
    "ridge_results_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"Ridge\",\n",
    "    \"Alpha\": alpha_value,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0971e7",
   "metadata": {},
   "source": [
    "Howto & Style - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c138dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: RandomForest\n",
      "n_estimators: 100\n",
      "RMSE: 0.4219\n",
      "R²: 0.9022\n",
      "Spearman: 0.9645\n"
     ]
    }
   ],
   "source": [
    "# RF 모델 정의 및 학습\n",
    "n_estimators = 100\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=-1, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# 성능 지표 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "\n",
    "# 출력\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: RandomForest\")\n",
    "print(\"n_estimators:\", n_estimators)\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", \"NaN\" if np.isnan(spearman_corr) else round(spearman_corr, 4))\n",
    "\n",
    "# 결과 저장\n",
    "rf_results_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"RandomForest\",\n",
    "    \"Alpha\": None,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a92c5",
   "metadata": {},
   "source": [
    "Howto & Style - Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3aa81e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: GradientBoosting\n",
      "n_estimators: 100\n",
      "RMSE: 0.6114\n",
      "R²: 0.7947\n",
      "Spearman: 0.9194\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting 모델 정의 및 학습\n",
    "n_estimators = 100\n",
    "gbr = GradientBoostingRegressor(n_estimators=n_estimators, random_state=42)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "# 성능 지표 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "\n",
    "# 출력\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: GradientBoosting\")\n",
    "print(\"n_estimators:\", n_estimators)\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", \"NaN\" if np.isnan(spearman_corr) else round(spearman_corr, 4))\n",
    "\n",
    "# 결과 저장\n",
    "gbr_results_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"GradientBoosting\",\n",
    "    \"Alpha\": None,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a639829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 결과 DataFrame 합치기\n",
    "all_results = pd.concat([\n",
    "    lasso_results_df,\n",
    "    linear_results_df,\n",
    "    ridge_results_df,\n",
    "    rf_results_df,\n",
    "    gbr_results_df\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4aa829e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화를 위한 변환 (wide → long)\n",
    "results_long = all_results.melt(\n",
    "    id_vars=\"Model\", \n",
    "    value_vars=[\"RMSE\", \"R²\", \"Spearman\"],\n",
    "    var_name=\"Metric\", \n",
    "    value_name=\"Score\"\n",
    ")\n",
    "\n",
    "# 선 그래프(line chart)로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric in results_long[\"Metric\"].unique():\n",
    "    subset = results_long[results_long[\"Metric\"] == metric]\n",
    "    plt.plot(subset[\"Model\"], subset[\"Score\"], marker='o', label=metric)\n",
    "\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c944262",
   "metadata": {},
   "source": [
    "Howto &Style 파라미터튜닝(베이지안 최적화 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "004e24fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: BayesianOptimization in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (0.0.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from BayesianOptimization) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0f17a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (4.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (1.21.5)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (1.4.32)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from optuna) (1.16.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: tomli in c:\\programdata\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8a764",
   "metadata": {},
   "source": [
    "Howto & Style - Lasso(베이지안 최적화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee578538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:01:59,316] A new study created in memory with name: no-name-37c64c1d-bb06-437f-bf75-f33e516c44ed\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+02, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+02, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+02, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+02, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+02, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:01,951] Trial 0 finished with value: 0.3365100063630832 and parameters: {'alpha': 0.00048091820917905867}. Best is trial 0 with value: 0.3365100063630832.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:02,081] Trial 1 finished with value: 1.7409845326648612 and parameters: {'alpha': 0.10255150712845014}. Best is trial 0 with value: 0.3365100063630832.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:02,212] Trial 2 finished with value: 1.7409845326648612 and parameters: {'alpha': 1.128365910296162}. Best is trial 0 with value: 0.3365100063630832.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.655e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.655e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+02, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+02, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.492e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:05,269] Trial 3 finished with value: 0.23973641023224576 and parameters: {'alpha': 0.00012078216144954077}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:05,400] Trial 4 finished with value: 1.7409845326648612 and parameters: {'alpha': 0.1418000943988166}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:05,585] Trial 5 finished with value: 1.3919110487092272 and parameters: {'alpha': 0.020390907558819032}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:05,745] Trial 6 finished with value: 1.556852880005729 and parameters: {'alpha': 0.034368138840214474}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:06,024] Trial 7 finished with value: 1.162356117038183 and parameters: {'alpha': 0.011221467373603388}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.534e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.323e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.207e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.377e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.569e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:09,166] Trial 8 finished with value: 0.24520173627235037 and parameters: {'alpha': 4.1990585387277785e-05}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:09,369] Trial 9 finished with value: 1.28017499232578 and parameters: {'alpha': 0.015409235675284717}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+02, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.830e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.361e+02, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.060e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+02, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:12,178] Trial 10 finished with value: 0.3257242344064004 and parameters: {'alpha': 0.0003984416017975738}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.117e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.926e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.974e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.887e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.814e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:15,286] Trial 11 finished with value: 0.26024576982086967 and parameters: {'alpha': 1.210240365817298e-05}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.039e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.701e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.841e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.912e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.664e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:18,273] Trial 12 finished with value: 0.26086954483861097 and parameters: {'alpha': 1.0990609984975743e-05}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+02, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.256e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+02, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.559e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+02, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:21,151] Trial 13 finished with value: 0.2686031527912498 and parameters: {'alpha': 0.00020349371685604857}. Best is trial 3 with value: 0.23973641023224576.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.095e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.019e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.107e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.494e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.755e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:24,157] Trial 14 finished with value: 0.23575864072846633 and parameters: {'alpha': 6.180581892819486e-05}. Best is trial 14 with value: 0.23575864072846633.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.707e+00, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e+00, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+00, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.162e+00, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:26,875] Trial 15 finished with value: 0.5626146669543299 and parameters: {'alpha': 0.0018879045176267125}. Best is trial 14 with value: 0.23575864072846633.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.235e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.596e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.754e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.728e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:29,769] Trial 16 finished with value: 0.23541512760392438 and parameters: {'alpha': 7.659954947315224e-05}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:31,678] Trial 17 finished with value: 0.6883083499649143 and parameters: {'alpha': 0.0029513078349684167}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.911e+00, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+00, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.483e+00, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:34,197] Trial 18 finished with value: 0.5442757772474758 and parameters: {'alpha': 0.0017541393014040923}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.094e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.845e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.114e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.614e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.625e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:37,103] Trial 19 finished with value: 0.23676561330418905 and parameters: {'alpha': 5.902885264946107e-05}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.332e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.432e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.156e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.433e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.019e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:40,176] Trial 20 finished with value: 0.24695799354142953 and parameters: {'alpha': 3.919227764836953e-05}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.781e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.516e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.777e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.577e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:43,171] Trial 21 finished with value: 0.239225445883181 and parameters: {'alpha': 5.4178439556432284e-05}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.200e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.001e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.874e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.661e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.388e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:45,894] Trial 22 finished with value: 0.37868932468679667 and parameters: {'alpha': 0.0007740752249579952}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.287e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.894e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.583e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.903e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.695e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:48,842] Trial 23 finished with value: 0.23725824090257955 and parameters: {'alpha': 0.00010214086458993898}. Best is trial 16 with value: 0.23541512760392438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.311e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.207e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.204e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.996e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.432e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:51,955] Trial 24 finished with value: 0.25513467139302903 and parameters: {'alpha': 2.3223645617546408e-05}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:52,083] Trial 25 finished with value: 1.7409845326648612 and parameters: {'alpha': 2.4783177966657832}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.409e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.999e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.546e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.679e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+02, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:54,966] Trial 26 finished with value: 0.2854405951557032 and parameters: {'alpha': 0.00024691569805545074}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:02:56,092] Trial 27 finished with value: 0.7736705975104801 and parameters: {'alpha': 0.0038640009199118505}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.339e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.662e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.755e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+02, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.779e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:02:59,149] Trial 28 finished with value: 0.23560148671789788 and parameters: {'alpha': 9.317771947607277e-05}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+02, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+02, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.511e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.966e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:02,172] Trial 29 finished with value: 0.2562160432175757 and parameters: {'alpha': 0.00016621076174483786}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+02, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+02, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+02, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+02, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+02, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:04,672] Trial 30 finished with value: 0.35270280954910316 and parameters: {'alpha': 0.0006145722603812584}. Best is trial 16 with value: 0.23541512760392438.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.973e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.479e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.387e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.750e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.993e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:07,747] Trial 31 finished with value: 0.23497872639591896 and parameters: {'alpha': 6.693664848964216e-05}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.485e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.921e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.951e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.831e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.289e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:10,844] Trial 32 finished with value: 0.2565429472964334 and parameters: {'alpha': 2.0157469986455966e-05}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.178e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.351e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.922e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.483e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.877e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:13,896] Trial 33 finished with value: 0.23553286540172186 and parameters: {'alpha': 8.479199202985474e-05}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.679e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+02, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.571e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.902e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.531e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:16,386] Trial 34 finished with value: 0.41254800541800674 and parameters: {'alpha': 0.0009635925651687421}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:16,529] Trial 35 finished with value: 1.7409845326648612 and parameters: {'alpha': 0.411474885699851}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.913e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.839e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.989e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.666e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.791e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:19,507] Trial 36 finished with value: 0.23773175218039158 and parameters: {'alpha': 0.00010459550099843673}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+02, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+02, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.332e+02, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.658e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+02, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:22,227] Trial 37 finished with value: 0.3284739643556501 and parameters: {'alpha': 0.0004165455219487722}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.436e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.839e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.881e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.756e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:25,285] Trial 38 finished with value: 0.2558013007961707 and parameters: {'alpha': 2.17205443082226e-05}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:25,429] Trial 39 finished with value: 1.7347627132678465 and parameters: {'alpha': 0.06880431135170229}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:25,945] Trial 40 finished with value: 1.0083091739342531 and parameters: {'alpha': 0.00745979242586685}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.945e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.844e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.948e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.687e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.767e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:28,952] Trial 41 finished with value: 0.2377088473505052 and parameters: {'alpha': 0.0001044370606586625}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.969e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.480e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.400e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.742e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.003e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:32,089] Trial 42 finished with value: 0.23498909311126073 and parameters: {'alpha': 6.711287095755168e-05}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.941e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.478e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.417e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.547e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+02, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:35,076] Trial 43 finished with value: 0.29514226769582275 and parameters: {'alpha': 0.00027105559488169417}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.276e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.009e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.845e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.547e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.158e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:38,325] Trial 44 finished with value: 0.25240865210882724 and parameters: {'alpha': 2.9927038981745132e-05}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.806e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.844e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+02, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.666e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.869e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:41,508] Trial 45 finished with value: 0.23783991826143075 and parameters: {'alpha': 0.00010531863558151598}. Best is trial 31 with value: 0.23497872639591896.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.298e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.663e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.045e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.978e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.929e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:44,955] Trial 46 finished with value: 0.2588177095297012 and parameters: {'alpha': 1.5115483245667163e-05}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:45,085] Trial 47 finished with value: 1.7409845326648612 and parameters: {'alpha': 8.87288749908627}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.196e+01, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.966e+01, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.203e+01, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.570e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.765e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:48,084] Trial 48 finished with value: 0.2359712553706713 and parameters: {'alpha': 6.105750552971304e-05}. Best is trial 31 with value: 0.23497872639591896.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\2454646385.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+02, tolerance: 4.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+02, tolerance: 4.666e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+02, tolerance: 4.621e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.933e+01, tolerance: 4.622e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.959e+01, tolerance: 4.575e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-06-08 20:03:50,799] Trial 49 finished with value: 0.26123358127401797 and parameters: {'alpha': 0.00018051475322254594}. Best is trial 31 with value: 0.23497872639591896.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: Lasso (Bayesian)\n",
      "Best Alpha: 6.693664848964216e-05\n",
      "RMSE: 0.5544\n",
      "R²: 0.8311\n",
      "Spearman: 0.9432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+02, tolerance: 5.771e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective_lasso(trial):\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
    "    model = Lasso(alpha=alpha)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "    return -score.mean()\n",
    "\n",
    "study_lasso = optuna.create_study(direction='minimize')\n",
    "study_lasso.optimize(objective_lasso, n_trials=50)\n",
    "\n",
    "# 튜닝된 모델로 최종 학습 및 평가\n",
    "best_alpha = study_lasso.best_params['alpha']\n",
    "lasso_best = Lasso(alpha=best_alpha)\n",
    "lasso_best.fit(X_train, y_train)\n",
    "y_pred = lasso_best.predict(X_test)\n",
    "\n",
    "# 성능 지표 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "# 출력\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: Lasso (Bayesian)\")\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", \"NaN\" if np.isnan(spearman_corr) else round(spearman_corr, 4))\n",
    "\n",
    "# 결과 저장\n",
    "lasso_optuna_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"Lasso (Bayesian)\",\n",
    "    \"Alpha\": best_alpha,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d182ee",
   "metadata": {},
   "source": [
    "Howto & Style - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3465ca9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: LinearRegression\n",
      "RMSE: 0.577\n",
      "R²: 0.8171\n",
      "Spearman: 0.9453\n"
     ]
    }
   ],
   "source": [
    "# LinearRegression 모델 정의 및 학습\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "y_pred = linear.predict(X_test)\n",
    "\n",
    "# 성능 지표 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "\n",
    "# 출력\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: LinearRegression\")\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", \"NaN\" if np.isnan(spearman_corr) else round(spearman_corr, 4))\n",
    "\n",
    "# 결과 저장\n",
    "linear_results_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"LinearRegression\",\n",
    "    \"Alpha\": None,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d17dc",
   "metadata": {},
   "source": [
    "Howto & Style - Ridge(베이지안 최적화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc8252e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:03:51,747] A new study created in memory with name: no-name-8b93a4c3-69f8-41b9-83ef-57684fc2e6a5\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.06278e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.02124e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.01399e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.9371e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.0813e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:51,898] Trial 0 finished with value: 0.24994382616567049 and parameters: {'alpha': 0.0013951887196694541}. Best is trial 0 with value: 0.24994382616567049.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:52,039] Trial 1 finished with value: 0.3187639115193811 and parameters: {'alpha': 2.098632361311513}. Best is trial 0 with value: 0.24994382616567049.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:52,170] Trial 2 finished with value: 0.2639048233257243 and parameters: {'alpha': 0.6975785628544364}. Best is trial 0 with value: 0.24994382616567049.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:52,309] Trial 3 finished with value: 0.43988273533260697 and parameters: {'alpha': 7.57211327842658}. Best is trial 0 with value: 0.24994382616567049.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.07857e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.07191e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.07941e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.99239e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.01644e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:52,450] Trial 4 finished with value: 0.24624359365533915 and parameters: {'alpha': 0.02039846818719719}. Best is trial 4 with value: 0.24624359365533915.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.30925e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.31234e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.30744e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.27615e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.28558e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:52,588] Trial 5 finished with value: 0.24880697122137532 and parameters: {'alpha': 0.008720105617746433}. Best is trial 4 with value: 0.24624359365533915.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.27951e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.27761e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.27371e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.24554e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.25434e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:03:52,730] Trial 6 finished with value: 0.2487339199017784 and parameters: {'alpha': 0.008496053787547518}. Best is trial 4 with value: 0.24624359365533915.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:54,095] Trial 7 finished with value: 0.2507792349659344 and parameters: {'alpha': 1.919102223910774e-05}. Best is trial 4 with value: 0.24624359365533915.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.90378e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.89474e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.89016e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.84714e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.86535e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:54,244] Trial 8 finished with value: 0.2475721482721911 and parameters: {'alpha': 0.01260381772499509}. Best is trial 4 with value: 0.24624359365533915.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.00076e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.02994e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.02794e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.92557e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.04367e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:54,390] Trial 9 finished with value: 0.2491670066906441 and parameters: {'alpha': 0.0013844420926291173}. Best is trial 4 with value: 0.24624359365533915.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:54,536] Trial 10 finished with value: 0.24044266099130507 and parameters: {'alpha': 0.17966184940372484}. Best is trial 10 with value: 0.24044266099130507.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:54,678] Trial 11 finished with value: 0.24208844312897657 and parameters: {'alpha': 0.23358258822557323}. Best is trial 10 with value: 0.24044266099130507.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:54,817] Trial 12 finished with value: 0.24156195681789341 and parameters: {'alpha': 0.21833978622190067}. Best is trial 10 with value: 0.24044266099130507.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:54,957] Trial 13 finished with value: 0.2400606465831318 and parameters: {'alpha': 0.10142735231325514}. Best is trial 13 with value: 0.2400606465831318.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:55,108] Trial 14 finished with value: 0.24002052576812102 and parameters: {'alpha': 0.10229281535145592}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:55,264] Trial 15 finished with value: 0.24298604207519786 and parameters: {'alpha': 0.047151152725246816}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.52858e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.04234e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.50914e-11): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.84419e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:55,641] Trial 16 finished with value: 0.2854701510569221 and parameters: {'alpha': 0.00040224501708363195}. Best is trial 14 with value: 0.24002052576812102.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:55,792] Trial 17 finished with value: 0.24204906635390394 and parameters: {'alpha': 0.05798798018345078}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:55,943] Trial 18 finished with value: 0.31142125193228354 and parameters: {'alpha': 1.8791282342837978}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:57,295] Trial 19 finished with value: 0.2507495357724117 and parameters: {'alpha': 8.669698814979244e-05}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.6623e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.60046e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.61859e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.51643e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.56212e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:57,432] Trial 20 finished with value: 0.24976633404816279 and parameters: {'alpha': 0.002433527831767501}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:57,578] Trial 21 finished with value: 0.24036130851881837 and parameters: {'alpha': 0.1763978638126248}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:57,723] Trial 22 finished with value: 0.24043990192960157 and parameters: {'alpha': 0.08781739013053169}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:57,867] Trial 23 finished with value: 0.27956682253394655 and parameters: {'alpha': 1.044988337583058}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:58,018] Trial 24 finished with value: 0.24512893444274447 and parameters: {'alpha': 0.3074916685354766}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:58,163] Trial 25 finished with value: 0.4178664909982256 and parameters: {'alpha': 6.275069177199856}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.58874e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.593e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.58053e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.4496e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.47572e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:58,315] Trial 26 finished with value: 0.24410103690748794 and parameters: {'alpha': 0.036968575166360464}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:58,455] Trial 27 finished with value: 0.2520333896442997 and parameters: {'alpha': 0.45309198111899557}. Best is trial 14 with value: 0.24002052576812102.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:03:58,602] Trial 28 finished with value: 0.23985003472623445 and parameters: {'alpha': 0.11629256605310229}. Best is trial 28 with value: 0.23985003472623445.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.05377e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.04137e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.01256e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.83043e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.96998e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:58,756] Trial 29 finished with value: 0.24975901168380416 and parameters: {'alpha': 0.0026796155574337933}. Best is trial 28 with value: 0.23985003472623445.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:58,901] Trial 30 finished with value: 0.24098105572831838 and parameters: {'alpha': 0.07496065092788622}. Best is trial 28 with value: 0.23985003472623445.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:59,040] Trial 31 finished with value: 0.23980437544566685 and parameters: {'alpha': 0.13705116067883344}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.49685e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.49792e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.48637e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.39101e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=4.41148e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:59,191] Trial 32 finished with value: 0.24491319451092708 and parameters: {'alpha': 0.02980876788031523}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:59,335] Trial 33 finished with value: 0.26793986439480577 and parameters: {'alpha': 0.7838325375227165}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:59,486] Trial 34 finished with value: 0.24002704442371797 and parameters: {'alpha': 0.10138265786853437}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:03:59,630] Trial 35 finished with value: 0.35343197718382807 and parameters: {'alpha': 3.2874888374267877}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.46267e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.45376e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.44611e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.39489e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.41949e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:03:59,776] Trial 36 finished with value: 0.24672116890733356 and parameters: {'alpha': 0.016329653490078904}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:03:59,923] Trial 37 finished with value: 0.2837426551745688 and parameters: {'alpha': 1.143944713815317}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=7.23354e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=7.27375e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=7.32901e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=7.08698e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=7.26317e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:04:00,070] Trial 38 finished with value: 0.24937362583234396 and parameters: {'alpha': 0.004867352709523388}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:04:00,207] Trial 39 finished with value: 0.2597931193277544 and parameters: {'alpha': 0.6116255055787179}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.66086e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.66109e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.65269e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.55906e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=3.58546e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:04:00,353] Trial 40 finished with value: 0.24547480465672938 and parameters: {'alpha': 0.024267285298932136}. Best is trial 31 with value: 0.23980437544566685.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:04:00,511] Trial 41 finished with value: 0.2397901693948797 and parameters: {'alpha': 0.1266301165417827}. Best is trial 41 with value: 0.2397901693948797.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:04:00,661] Trial 42 finished with value: 0.24026491995448457 and parameters: {'alpha': 0.0926975716176022}. Best is trial 41 with value: 0.2397901693948797.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:19:33,389] Trial 44 finished with value: 0.243493780862797 and parameters: {'alpha': 0.26960227908936313}. Best is trial 41 with value: 0.2397901693948797.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.2872e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.29473e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.28513e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.25603e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=1.26759e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "[I 2025-06-08 20:19:33,754] Trial 45 finished with value: 0.2486882664121312 and parameters: {'alpha': 0.008574341846651911}. Best is trial 41 with value: 0.2397901693948797.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:19:34,122] Trial 46 finished with value: 0.2521285492253807 and parameters: {'alpha': 0.4547435937557207}. Best is trial 41 with value: 0.2397901693948797.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:19:34,355] Trial 47 finished with value: 0.23979112888500204 and parameters: {'alpha': 0.13188728391923418}. Best is trial 41 with value: 0.2397901693948797.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:19:34,589] Trial 48 finished with value: 0.31795504493885185 and parameters: {'alpha': 2.0738418773288694}. Best is trial 41 with value: 0.2397901693948797.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\3443496583.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
      "[I 2025-06-08 20:19:34,817] Trial 49 finished with value: 0.24001207453439433 and parameters: {'alpha': 0.1557397092263036}. Best is trial 41 with value: 0.2397901693948797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: Ridge (Bayesian)\n",
      "Alpha: 0.1266301165417827\n",
      "RMSE: 0.5523\n",
      "R²: 0.8324\n",
      "Spearman: 0.9461\n"
     ]
    }
   ],
   "source": [
    "def objective_ridge(trial):\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-5, 10)\n",
    "    model = Ridge(alpha=alpha)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "    return -score.mean()\n",
    "\n",
    "study_ridge = optuna.create_study(direction='minimize')\n",
    "study_ridge.optimize(objective_ridge, n_trials=50)\n",
    "\n",
    "# 최적 모델 적용\n",
    "best_alpha = study_ridge.best_params['alpha']\n",
    "ridge_best = Ridge(alpha=best_alpha)\n",
    "ridge_best.fit(X_train, y_train)\n",
    "y_pred = ridge_best.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: Ridge (Bayesian)\")\n",
    "print(\"Alpha:\", best_alpha)\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", round(spearman_corr, 4) if not np.isnan(spearman_corr) else \"NaN\")\n",
    "\n",
    "ridge_optuna_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"Ridge (Bayesian)\",\n",
    "    \"Alpha\": best_alpha,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc6b69",
   "metadata": {},
   "source": [
    "Howto & Style - RF(베이지안 최적화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c597da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:19:34,882] A new study created in memory with name: no-name-55944184-37c1-49e4-a30a-45e28b50ff3d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1026aeb801ef4317b7e85beb8e08d22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:19:47,097] Trial 0 finished with value: 0.7672698403673034 and parameters: {'n_estimators': 497, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7672698403673034.\n",
      "[I 2025-06-08 20:19:51,500] Trial 1 finished with value: 0.31969032058201496 and parameters: {'n_estimators': 453, 'max_depth': 37, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 1 with value: 0.31969032058201496.\n",
      "[I 2025-06-08 20:19:54,028] Trial 2 finished with value: 0.30539807405096514 and parameters: {'n_estimators': 258, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.30539807405096514.\n",
      "[I 2025-06-08 20:20:03,145] Trial 3 finished with value: 0.21523623353217883 and parameters: {'n_estimators': 341, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.21523623353217883.\n",
      "[I 2025-06-08 20:20:09,648] Trial 4 finished with value: 0.24210679782879319 and parameters: {'n_estimators': 388, 'max_depth': 44, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 3 with value: 0.21523623353217883.\n",
      "[I 2025-06-08 20:20:12,424] Trial 5 finished with value: 0.31768160123520245 and parameters: {'n_estimators': 255, 'max_depth': 41, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 3 with value: 0.21523623353217883.\n",
      "[I 2025-06-08 20:20:15,478] Trial 6 finished with value: 0.2404739875536381 and parameters: {'n_estimators': 116, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.21523623353217883.\n",
      "[I 2025-06-08 20:20:19,432] Trial 7 finished with value: 0.21075798649184854 and parameters: {'n_estimators': 280, 'max_depth': 44, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 7 with value: 0.21075798649184854.\n",
      "[I 2025-06-08 20:20:29,085] Trial 8 finished with value: 0.2888635008201206 and parameters: {'n_estimators': 472, 'max_depth': 33, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.21075798649184854.\n",
      "[I 2025-06-08 20:20:36,213] Trial 9 finished with value: 0.25453556415097356 and parameters: {'n_estimators': 332, 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.21075798649184854.\n",
      "[I 2025-06-08 20:20:38,588] Trial 10 finished with value: 0.23664426265443939 and parameters: {'n_estimators': 156, 'max_depth': 46, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 7 with value: 0.21075798649184854.\n",
      "[I 2025-06-08 20:20:48,487] Trial 11 finished with value: 0.20326308132883686 and parameters: {'n_estimators': 353, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:20:53,125] Trial 12 finished with value: 0.22650439423030147 and parameters: {'n_estimators': 211, 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:20:57,609] Trial 13 finished with value: 0.26455093655492906 and parameters: {'n_estimators': 397, 'max_depth': 31, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:02,210] Trial 14 finished with value: 0.20583403274646436 and parameters: {'n_estimators': 288, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:12,416] Trial 15 finished with value: 0.22776153450615821 and parameters: {'n_estimators': 383, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:15,645] Trial 16 finished with value: 0.20564517117881817 and parameters: {'n_estimators': 194, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:18,205] Trial 17 finished with value: 0.7638979492984035 and parameters: {'n_estimators': 170, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:23,475] Trial 18 finished with value: 0.24623141581669628 and parameters: {'n_estimators': 219, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:27,198] Trial 19 finished with value: 0.343979513942718 and parameters: {'n_estimators': 346, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:32,852] Trial 20 finished with value: 0.20732827751304206 and parameters: {'n_estimators': 212, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:37,780] Trial 21 finished with value: 0.20613957958820428 and parameters: {'n_estimators': 304, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:42,854] Trial 22 finished with value: 0.20442830154143787 and parameters: {'n_estimators': 302, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:49,180] Trial 23 finished with value: 0.23626125004915033 and parameters: {'n_estimators': 407, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:50,838] Trial 24 finished with value: 0.21169442982650674 and parameters: {'n_estimators': 106, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:56,005] Trial 25 finished with value: 0.2360597488298798 and parameters: {'n_estimators': 324, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:21:58,527] Trial 26 finished with value: 0.38402293136839916 and parameters: {'n_estimators': 245, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:00,672] Trial 27 finished with value: 0.24545896447020335 and parameters: {'n_estimators': 172, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:09,707] Trial 28 finished with value: 0.2669377334937096 and parameters: {'n_estimators': 422, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:19,145] Trial 29 finished with value: 0.2263831521184306 and parameters: {'n_estimators': 355, 'max_depth': 33, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:24,077] Trial 30 finished with value: 0.20665399749270907 and parameters: {'n_estimators': 366, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:28,829] Trial 31 finished with value: 0.20629688368724153 and parameters: {'n_estimators': 304, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:33,058] Trial 32 finished with value: 0.2100550649472288 and parameters: {'n_estimators': 291, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:22:36,826] Trial 33 finished with value: 0.20910424182777312 and parameters: {'n_estimators': 271, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:41,159] Trial 34 finished with value: 0.2057897376604756 and parameters: {'n_estimators': 235, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:44,058] Trial 35 finished with value: 0.26780011320439173 and parameters: {'n_estimators': 237, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:47,677] Trial 36 finished with value: 0.20529367835673087 and parameters: {'n_estimators': 191, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:49,327] Trial 37 finished with value: 0.23180729319327417 and parameters: {'n_estimators': 150, 'max_depth': 37, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:54,040] Trial 38 finished with value: 0.23464572354515031 and parameters: {'n_estimators': 187, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:22:58,248] Trial 39 finished with value: 0.2896985120407662 and parameters: {'n_estimators': 450, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:23:00,775] Trial 40 finished with value: 0.5796340038971993 and parameters: {'n_estimators': 325, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:23:03,345] Trial 41 finished with value: 0.20702461141085374 and parameters: {'n_estimators': 135, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.20326308132883686.\n",
      "[I 2025-06-08 20:23:07,838] Trial 42 finished with value: 0.20176539836762195 and parameters: {'n_estimators': 192, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 42 with value: 0.20176539836762195.\n",
      "[I 2025-06-08 20:23:12,965] Trial 43 finished with value: 0.19991748084978866 and parameters: {'n_estimators': 194, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 43 with value: 0.19991748084978866.\n",
      "[I 2025-06-08 20:23:19,648] Trial 44 finished with value: 0.2011788198583929 and parameters: {'n_estimators': 256, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 43 with value: 0.19991748084978866.\n",
      "[I 2025-06-08 20:23:26,193] Trial 45 finished with value: 0.2001988526125038 and parameters: {'n_estimators': 254, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 43 with value: 0.19991748084978866.\n",
      "[I 2025-06-08 20:23:31,636] Trial 46 finished with value: 0.2895521412157807 and parameters: {'n_estimators': 275, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 43 with value: 0.19991748084978866.\n",
      "[I 2025-06-08 20:23:38,322] Trial 47 finished with value: 0.2009574927226834 and parameters: {'n_estimators': 249, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 43 with value: 0.19991748084978866.\n",
      "[I 2025-06-08 20:23:42,201] Trial 48 finished with value: 0.23478508636747605 and parameters: {'n_estimators': 255, 'max_depth': 37, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 43 with value: 0.19991748084978866.\n",
      "[I 2025-06-08 20:23:48,092] Trial 49 finished with value: 0.20010558731253159 and parameters: {'n_estimators': 226, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 43 with value: 0.19991748084978866.\n",
      "Category: Howto & Style\n",
      "Model: RandomForest (Bayesian)\n",
      "Params: {'n_estimators': 194, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "RMSE: 0.428\n",
      "R²: 0.8994\n",
      "Spearman: 0.9633\n"
     ]
    }
   ],
   "source": [
    "def objective_rf(trial):\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 5, 50),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        max_features=trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),  # ✅ 'auto' 제거\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    score = cross_val_score(\n",
    "        model, X_train, y_train,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=3,\n",
    "        error_score=np.nan  # ✅ 에러 방지\n",
    "    )\n",
    "    return -np.nanmean(score)  # 모든 score가 nan인 경우 대비\n",
    "\n",
    "\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(objective_rf, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "best_params_rf = study_rf.best_params\n",
    "rf_best = RandomForestRegressor(**best_params_rf, random_state=42, n_jobs=-1)\n",
    "rf_best.fit(X_train, y_train)\n",
    "y_pred = rf_best.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: RandomForest (Bayesian)\")\n",
    "print(\"Params:\", best_params_rf)\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", round(spearman_corr, 4) if not np.isnan(spearman_corr) else \"NaN\")\n",
    "\n",
    "rf_optuna_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"RandomForest (Bayesian)\",\n",
    "    \"Alpha\": None,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6e74d",
   "metadata": {},
   "source": [
    "Howto & Style - Gradient(베이지안 최적화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb721cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 20:23:50,317] A new study created in memory with name: no-name-c6ee2424-a081-4676-aac9-a5b6fdff1542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca6ae37e15f4f9698e3475813977af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Boosting 튜닝 중:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 20:28:33,116] Trial 0 finished with value: 0.19334420047601616 and parameters: {'n_estimators': 305, 'learning_rate': 0.046397052138780585, 'max_depth': 4, 'min_samples_split': 9, 'subsample': 0.6372973254860087}. Best is trial 0 with value: 0.19334420047601616.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 20:46:34,210] Trial 1 finished with value: 0.16409487145549267 and parameters: {'n_estimators': 408, 'learning_rate': 0.012923565593202298, 'max_depth': 10, 'min_samples_split': 6, 'subsample': 0.9982886302063038}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 20:55:22,554] Trial 2 finished with value: 0.1659569758241642 and parameters: {'n_estimators': 243, 'learning_rate': 0.17385342212784846, 'max_depth': 8, 'min_samples_split': 8, 'subsample': 0.7629348318779707}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 21:04:56,428] Trial 3 finished with value: 0.1690300290443408 and parameters: {'n_estimators': 356, 'learning_rate': 0.025175150421973075, 'max_depth': 6, 'min_samples_split': 6, 'subsample': 0.8052339130158341}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 21:35:42,912] Trial 4 finished with value: 0.16665595518300289 and parameters: {'n_estimators': 399, 'learning_rate': 0.23618373266267742, 'max_depth': 7, 'min_samples_split': 2, 'subsample': 0.8896126988864397}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 21:39:44,101] Trial 5 finished with value: 0.1752978826701784 and parameters: {'n_estimators': 120, 'learning_rate': 0.15141275320795491, 'max_depth': 9, 'min_samples_split': 7, 'subsample': 0.6511873381421487}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 21:54:26,183] Trial 6 finished with value: 0.16557049453405326 and parameters: {'n_estimators': 377, 'learning_rate': 0.03430827089152181, 'max_depth': 8, 'min_samples_split': 4, 'subsample': 0.9795743972246855}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 22:02:45,287] Trial 7 finished with value: 0.16694323938929645 and parameters: {'n_estimators': 208, 'learning_rate': 0.03713644665763677, 'max_depth': 10, 'min_samples_split': 7, 'subsample': 0.6378009131401021}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 22:14:56,723] Trial 8 finished with value: 0.1648473800055902 and parameters: {'n_estimators': 271, 'learning_rate': 0.1383656910835608, 'max_depth': 9, 'min_samples_split': 3, 'subsample': 0.9319524326190431}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 22:23:49,308] Trial 9 finished with value: 0.17920287916861322 and parameters: {'n_estimators': 387, 'learning_rate': 0.02213031581150859, 'max_depth': 5, 'min_samples_split': 5, 'subsample': 0.8816601182315954}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 22:31:38,963] Trial 10 finished with value: 0.5729177810408995 and parameters: {'n_estimators': 500, 'learning_rate': 0.010879531662712577, 'max_depth': 3, 'min_samples_split': 10, 'subsample': 0.991817390942782}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 22:54:05,762] Trial 11 finished with value: 0.16455227740598397 and parameters: {'n_estimators': 485, 'learning_rate': 0.09101153595734522, 'max_depth': 10, 'min_samples_split': 2, 'subsample': 0.9223578181591099}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-08 23:18:49,611] Trial 12 finished with value: 0.16692633957281133 and parameters: {'n_estimators': 489, 'learning_rate': 0.08801612386797593, 'max_depth': 10, 'min_samples_split': 2, 'subsample': 0.8337689918779899}. Best is trial 1 with value: 0.16409487145549267.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-08 23:47:01,833] Trial 13 finished with value: 0.1632464689026011 and parameters: {'n_estimators': 447, 'learning_rate': 0.07476411542392467, 'max_depth': 10, 'min_samples_split': 4, 'subsample': 0.9312944186561968}. Best is trial 13 with value: 0.1632464689026011.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 00:01:00,830] Trial 14 finished with value: 0.161991347719279 and parameters: {'n_estimators': 423, 'learning_rate': 0.012121612447705623, 'max_depth': 8, 'min_samples_split': 5, 'subsample': 0.9964678981264736}. Best is trial 14 with value: 0.161991347719279.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 00:16:30,224] Trial 15 finished with value: 0.16548032047980443 and parameters: {'n_estimators': 445, 'learning_rate': 0.07866684191377708, 'max_depth': 8, 'min_samples_split': 4, 'subsample': 0.7586563741166306}. Best is trial 14 with value: 0.161991347719279.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 00:27:45,186] Trial 16 finished with value: 0.1645041551029349 and parameters: {'n_estimators': 344, 'learning_rate': 0.017849016198817784, 'max_depth': 7, 'min_samples_split': 4, 'subsample': 0.9409221140765377}. Best is trial 14 with value: 0.161991347719279.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 00:46:46,837] Trial 17 finished with value: 0.1633071570888248 and parameters: {'n_estimators': 428, 'learning_rate': 0.05521679609856089, 'max_depth': 9, 'min_samples_split': 5, 'subsample': 0.8592335936115643}. Best is trial 14 with value: 0.161991347719279.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 00:55:25,167] Trial 18 finished with value: 0.1621554674995189 and parameters: {'n_estimators': 326, 'learning_rate': 0.061797132595162105, 'max_depth': 6, 'min_samples_split': 5, 'subsample': 0.7014515934860877}. Best is trial 14 with value: 0.161991347719279.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 01:03:14,781] Trial 19 finished with value: 0.19553068416274808 and parameters: {'n_estimators': 324, 'learning_rate': 0.0152061343052097, 'max_depth': 6, 'min_samples_split': 5, 'subsample': 0.7024203632508758}. Best is trial 14 with value: 0.161991347719279.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 01:06:28,066] Trial 20 finished with value: 0.2680124925015235 and parameters: {'n_estimators': 160, 'learning_rate': 0.02769802169666399, 'max_depth': 5, 'min_samples_split': 7, 'subsample': 0.7198008937745564}. Best is trial 14 with value: 0.161991347719279.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 01:19:27,434] Trial 21 finished with value: 0.16040243607962326 and parameters: {'n_estimators': 453, 'learning_rate': 0.06081406330923992, 'max_depth': 7, 'min_samples_split': 3, 'subsample': 0.6966060419125726}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 01:30:16,225] Trial 22 finished with value: 0.16399449017696952 and parameters: {'n_estimators': 456, 'learning_rate': 0.05676332284285007, 'max_depth': 7, 'min_samples_split': 3, 'subsample': 0.6061170188751573}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 01:38:52,782] Trial 23 finished with value: 0.1726999792083421 and parameters: {'n_estimators': 353, 'learning_rate': 0.11326408233310624, 'max_depth': 6, 'min_samples_split': 3, 'subsample': 0.6985358357436982}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 01:44:11,603] Trial 24 finished with value: 0.17512834960112675 and parameters: {'n_estimators': 255, 'learning_rate': 0.043500657832862784, 'max_depth': 5, 'min_samples_split': 6, 'subsample': 0.742997630025002}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 01:56:37,452] Trial 25 finished with value: 0.17128287914131168 and parameters: {'n_estimators': 418, 'learning_rate': 0.06426840789981482, 'max_depth': 7, 'min_samples_split': 5, 'subsample': 0.6712966678284236}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 02:07:21,287] Trial 26 finished with value: 0.17323888052201206 and parameters: {'n_estimators': 290, 'learning_rate': 0.11181937575615475, 'max_depth': 8, 'min_samples_split': 3, 'subsample': 0.7815921307035794}. Best is trial 21 with value: 0.16040243607962326.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 02:20:29,972] Trial 27 finished with value: 0.16395040027793398 and parameters: {'n_estimators': 469, 'learning_rate': 0.033586456233015115, 'max_depth': 6, 'min_samples_split': 6, 'subsample': 0.8227103064482854}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 02:26:50,654] Trial 28 finished with value: 0.26430635279437525 and parameters: {'n_estimators': 380, 'learning_rate': 0.019291373745341376, 'max_depth': 4, 'min_samples_split': 4, 'subsample': 0.7324037083470806}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 02:31:13,164] Trial 29 finished with value: 0.19101669446919597 and parameters: {'n_estimators': 297, 'learning_rate': 0.04706373848420359, 'max_depth': 4, 'min_samples_split': 9, 'subsample': 0.6030308401188145}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 02:40:16,658] Trial 30 finished with value: 0.1690217118728389 and parameters: {'n_estimators': 323, 'learning_rate': 0.04525694401868017, 'max_depth': 7, 'min_samples_split': 5, 'subsample': 0.6872272438550978}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 03:00:49,605] Trial 31 finished with value: 0.16808960798738007 and parameters: {'n_estimators': 441, 'learning_rate': 0.0666235599408344, 'max_depth': 9, 'min_samples_split': 4, 'subsample': 0.9672951659515419}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 03:20:53,998] Trial 32 finished with value: 0.16222768017005643 and parameters: {'n_estimators': 469, 'learning_rate': 0.07544199463970414, 'max_depth': 8, 'min_samples_split': 3, 'subsample': 0.9568272662286298}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 03:37:40,959] Trial 33 finished with value: 0.16346060781794286 and parameters: {'n_estimators': 414, 'learning_rate': 0.09100590007227014, 'max_depth': 8, 'min_samples_split': 3, 'subsample': 0.9044354104368457}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 03:57:55,848] Trial 34 finished with value: 0.16972008373087158 and parameters: {'n_estimators': 469, 'learning_rate': 0.1128819372239181, 'max_depth': 8, 'min_samples_split': 2, 'subsample': 0.9629787000022344}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 04:05:08,150] Trial 35 finished with value: 0.17418560120733906 and parameters: {'n_estimators': 216, 'learning_rate': 0.24368394659763642, 'max_depth': 7, 'min_samples_split': 6, 'subsample': 0.9582662775291804}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 04:14:49,175] Trial 36 finished with value: 0.17563880489746564 and parameters: {'n_estimators': 403, 'learning_rate': 0.19010801333330557, 'max_depth': 6, 'min_samples_split': 3, 'subsample': 0.795437991040832}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 04:41:03,490] Trial 37 finished with value: 0.16442963010057046 and parameters: {'n_estimators': 470, 'learning_rate': 0.02820466782157798, 'max_depth': 9, 'min_samples_split': 8, 'subsample': 0.9986964561739737}. Best is trial 21 with value: 0.16040243607962326.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 04:53:47,977] Trial 38 finished with value: 0.15932820914066334 and parameters: {'n_estimators': 428, 'learning_rate': 0.049434403101785845, 'max_depth': 7, 'min_samples_split': 6, 'subsample': 0.8635162882012001}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 05:00:06,473] Trial 39 finished with value: 0.24931278816034533 and parameters: {'n_estimators': 367, 'learning_rate': 0.013340681578549545, 'max_depth': 5, 'min_samples_split': 6, 'subsample': 0.6642485333327602}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 05:09:19,657] Trial 40 finished with value: 0.211386749317531 and parameters: {'n_estimators': 396, 'learning_rate': 0.010343047942793906, 'max_depth': 6, 'min_samples_split': 7, 'subsample': 0.847004066650115}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 05:23:34,540] Trial 41 finished with value: 0.1618427204751842 and parameters: {'n_estimators': 423, 'learning_rate': 0.03795524456885571, 'max_depth': 8, 'min_samples_split': 5, 'subsample': 0.8680730240237597}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 05:36:05,767] Trial 42 finished with value: 0.16436030599416665 and parameters: {'n_estimators': 425, 'learning_rate': 0.03888020680349516, 'max_depth': 7, 'min_samples_split': 5, 'subsample': 0.867002440171272}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 05:55:05,843] Trial 43 finished with value: 0.16261687429434565 and parameters: {'n_estimators': 428, 'learning_rate': 0.05244609435820311, 'max_depth': 8, 'min_samples_split': 6, 'subsample': 0.7759025066527359}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 06:04:54,890] Trial 44 finished with value: 0.16496671747461022 and parameters: {'n_estimators': 338, 'learning_rate': 0.03176057531703184, 'max_depth': 7, 'min_samples_split': 7, 'subsample': 0.8954740170054851}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 06:18:54,334] Trial 45 finished with value: 0.1623593656289627 and parameters: {'n_estimators': 385, 'learning_rate': 0.060744045005319124, 'max_depth': 9, 'min_samples_split': 5, 'subsample': 0.804718633880999}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 06:28:58,308] Trial 46 finished with value: 0.16447219092790147 and parameters: {'n_estimators': 365, 'learning_rate': 0.02248511888767756, 'max_depth': 7, 'min_samples_split': 4, 'subsample': 0.82261805216696}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 06:42:55,073] Trial 47 finished with value: 0.16449691672058178 and parameters: {'n_estimators': 492, 'learning_rate': 0.0392815142575416, 'max_depth': 8, 'min_samples_split': 8, 'subsample': 0.6332390697872775}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 06:58:00,786] Trial 48 finished with value: 0.16805279684088273 and parameters: {'n_estimators': 404, 'learning_rate': 0.05277476839301804, 'max_depth': 8, 'min_samples_split': 7, 'subsample': 0.8720030436309064}. Best is trial 38 with value: 0.15932820914066334.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19608\\459554988.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "[I 2025-06-09 07:01:03,131] Trial 49 finished with value: 0.17297478367659927 and parameters: {'n_estimators': 110, 'learning_rate': 0.06775871831611939, 'max_depth': 6, 'min_samples_split': 5, 'subsample': 0.9088011775249621}. Best is trial 38 with value: 0.15932820914066334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Howto & Style\n",
      "Model: GradientBoosting (Bayesian)\n",
      "Params: {'n_estimators': 428, 'learning_rate': 0.049434403101785845, 'max_depth': 7, 'min_samples_split': 6, 'subsample': 0.8635162882012001}\n",
      "RMSE: 0.3858\n",
      "R²: 0.9182\n",
      "Spearman: 0.9681\n"
     ]
    }
   ],
   "source": [
    "def objective_gbr(trial):\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        learning_rate=trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        random_state=42\n",
    "    )\n",
    "    score = cross_val_score(\n",
    "        model, X_train, y_train,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=3,\n",
    "        error_score=np.nan  # ✅ 이거 하나가 핵심!\n",
    "    )\n",
    "    return -np.nanmean(score)  # 모든 trial 실패 시에도 안전하게 작동\n",
    "\n",
    "\n",
    "study_gbr = optuna.create_study(direction='minimize')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "for _ in tqdm(range(50), desc=\"Gradient Boosting 튜닝 중\"):\n",
    "    study_gbr.optimize(objective_gbr, n_trials=1)\n",
    "\n",
    "best_params_gbr = study_gbr.best_params\n",
    "gbr_best = GradientBoostingRegressor(**best_params_gbr, random_state=42)\n",
    "gbr_best.fit(X_train, y_train)\n",
    "y_pred = gbr_best.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr = spearmanr(y_test, y_pred).correlation if np.std(y_pred) > 0 else np.nan\n",
    "\n",
    "print(\"Category:\", cat_name)\n",
    "print(\"Model: GradientBoosting (Bayesian)\")\n",
    "print(\"Params:\", best_params_gbr)\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R²:\", round(r2, 4))\n",
    "print(\"Spearman:\", round(spearman_corr, 4) if not np.isnan(spearman_corr) else \"NaN\")\n",
    "\n",
    "gbr_optuna_df = pd.DataFrame([{\n",
    "    \"Category\": cat_name,\n",
    "    \"Model\": \"GradientBoosting (Bayesian)\",\n",
    "    \"Alpha\": None,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R²\": r2,\n",
    "    \"Spearman\": spearman_corr\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d01ccde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 결과 DataFrame 합치기\n",
    "all_results = pd.concat([\n",
    "    lasso_optuna_df,\n",
    "    linear_results_df,\n",
    "    ridge_optuna_df,\n",
    "    rf_optuna_df,\n",
    "    gbr_optuna_df\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0ca84cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#시각화를 위한 변환 (wide → long)\n",
    "results_long = all_results.melt(\n",
    "    id_vars=\"Model\", \n",
    "    value_vars=[\"RMSE\", \"R²\", \"Spearman\"],\n",
    "    var_name=\"Metric\", \n",
    "    value_name=\"Score\"\n",
    ")\n",
    "\n",
    "# 선 그래프(line chart)로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric in results_long[\"Metric\"].unique():\n",
    "    subset = results_long[results_long[\"Metric\"] == metric]\n",
    "    plt.plot(subset[\"Model\"], subset[\"Score\"], marker='o', label=metric)\n",
    "\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867026b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
